{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZd3hUaaEjkU",
        "outputId": "1c8f2ab3-7d39-4f67-c984-f2a459811ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Grit CLI from https://github.com/getgrit/gritql/releases/latest/download/grit-x86_64-unknown-linux-gnu.tar.gz\n",
            "\n",
            "\u001b[2K\u001b[1A\n",
            "\u001b[2K\u001b[1A\n",
            "\u001b[1m\u001b[2mAnalyzing\u001b[0m \u001b[1m\u001b[2mFinding files                                                         \u001b[0m\n",
            "\u001b[2K\u001b[2AProcessed 0 files and found 0 matches\n"
          ]
        }
      ],
      "source": [
        "!openai migrate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtNQc4w8EykQ",
        "outputId": "b409e634-353b-4cad-cd45-2e2a7cf958ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.59.9\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "print(openai.__version__)  # This will display the installed version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw8sdesxFijw",
        "outputId": "8e485d50-e72e-419b-a184-f7dcfb913808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.019088275730609894, 0.007378327194601297, -0.004212402272969484, 0.00018307143182028085, 0.0028894031420350075, 0.013895628973841667, -0.0029904081020504236, -0.006742492783814669, -0.019777094945311546, -0.01533950213342905, -0.006742492783814669, 0.025473112240433693, -0.0002965984749607742, 0.002493662526831031, 0.004358114209026098, 0.01690259575843811, 0.012504740618169308, 0.005460889078676701, 0.013736669905483723, -0.023207951337099075, -0.005825169384479523, -0.004798561800271273, 0.00820623617619276, 0.020426176488399506, -0.0295398011803627, -0.017273498699069023, 0.013345897197723389, -0.02951330877840519, 0.010073999874293804, -0.01773712784051895, 0.012928630225360394, -0.021088503301143646, 0.003146055154502392, -0.018333222717046738, -0.013180314563214779, 0.0023396715987473726, 0.002887747483327985, -0.0280561875551939, 0.03528880327939987, -0.011325797997415066, -0.002144285012036562, 0.011425147764384747, 0.01386913564056158, -0.021287202835083008, -0.019088275730609894, -0.0032901111990213394, 0.0022187966387718916, -0.02163161337375641, -0.0016549905994907022, 0.008722851984202862, 0.03081147000193596, -0.005533745512366295, -0.0280561875551939, -8.781012002145872e-05, -0.004212402272969484, 0.010338930413126945, -0.021909790113568306, 0.032083138823509216, 0.022267445921897888, 0.0009189792326651514, -0.014134066179394722, 0.01402809377759695, -0.0024969743099063635, 0.0018114653648808599, -0.01533950213342905, 0.0020532149355858564, -0.0025135325267910957, 0.01188215333968401, 0.02114148996770382, 0.018319975584745407, 0.020108260214328766, 0.01673039048910141, 0.013001486659049988, -0.01271006278693676, 0.010133609175682068, 0.009981273673474789, -0.015207036398351192, 0.003407674375921488, 0.010312437079846859, 0.005643029231578112, 0.005639717914164066, -0.031208867207169533, -0.009881924837827682, 0.03462647646665573, 0.006219254340976477, 0.0029092731419950724, -0.012994863092899323, 0.023366909474134445, -0.020585134625434875, -0.013067719526588917, -0.015326255932450294, 0.018889576196670532, -0.007040540222078562, 0.02311522513628006, -0.010007767006754875, 0.03719630464911461, -0.002660900354385376, 0.022890035063028336, 0.005692704115062952, -0.01704830676317215, 0.00934543926268816, 0.0023545739240944386, -0.00802740827202797, -0.009371932595968246, -0.03870641067624092, -0.0020068520680069923, 0.01409432664513588, -0.015498461201786995, 0.02477104403078556, 0.027287889271974564, -0.01181592047214508, 0.009749459102749825, -0.01106749102473259, -0.0318182073533535, 0.0019058471079915762, 0.015365995466709137, 0.003041738411411643, -0.030414072796702385, -0.015220283530652523, -0.003293422982096672, 0.007358457427471876, 0.027287889271974564, 0.017803359776735306, -0.00676236255094409, 0.01969761587679386, 0.0032917670905590057, -0.002487039426341653, -0.03083796240389347, -0.020068520680069923, -0.017975565046072006, 0.007643258199095726, 0.010795935988426208, 0.008669865317642689, 0.019803589209914207, -0.018134523183107376, 0.03552724048495293, -0.03229508176445961, 0.00949777476489544, -0.03629554063081741, -0.0059874397702515125, 0.01870412565767765, 0.025459865108132362, -2.3582477297168225e-05, -0.004616422113031149, 0.0010117051424458623, 0.006143086589872837, -0.008080394007265568, -0.012531233951449394, 0.01426653191447258, -0.021724337711930275, 0.0024622019845992327, 0.00974283553659916, 0.005745690315961838, 0.000830806908197701, -0.008325455710291862, 0.039289262145757675, 0.0044938912615180016, -0.007457806263118982, -0.01789608597755432, -0.018889576196670532, 0.007510792464017868, 0.006033802404999733, -0.004911157768219709, 0.001384264207445085, 0.028162160888314247, 0.03722279891371727, 0.0038083824329078197, -0.006828595418483019, 0.003967341035604477, -0.016332993283867836, -0.02462533302605152, 0.03210963308811188, -0.04294530674815178, 0.004262076690793037, -0.01904853619635105, 0.008597009815275669, 0.007928058505058289, 0.014968599192798138, -0.010093869641423225, -0.027287889271974564, -0.03913030028343201, 0.004606486763805151, 0.01163709256798029, 0.011319175362586975, -0.010266074910759926, -0.01788283884525299, 0.010213088244199753, -0.013001486659049988, 0.007365080527961254, -0.008173120208084583, 0.024360401555895805, 0.02818865329027176, 0.012888890691101551, -0.0011739752953872085, -0.6850054860115051, 0.006901451386511326, 0.042415447533130646, -0.019962547346949577, 0.02115473710000515, 0.035659708082675934, 0.012842527590692043, -0.01524677686393261, -0.024704812094569206, 0.0299901831895113, -0.01653169095516205, -0.007113396190106869, -0.01884983666241169, -0.010160102508962154, 0.0035037118941545486, -0.002934110350906849, 0.001561436802148819, -0.013273040764033794, 0.005401279777288437, 0.02085006609559059, 0.004682654514908791, 0.018571659922599792, -0.005099921021610498, 0.0024555788841098547, -0.0054840706288814545, 0.01933996006846428, -0.0015738554066047072, -0.007365080527961254, 0.002896026475355029, 0.029062924906611443, -0.021379927173256874, 0.01041178684681654, 0.010338930413126945, 0.01785634644329548, 0.044375933706760406, -0.014372504316270351, -0.022240953519940376, -0.011425147764384747, -0.0006499087321572006, 0.0001179770624730736, -0.023366909474134445, -0.0008237696602009237, 0.01345186959952116, -0.011193333193659782, -0.013617451302707195, 0.005636406131088734, 0.01466392818838358, -0.009716343134641647, -0.006288798525929451, 0.003940848167985678, -0.005331735592335463, 0.02347288280725479, -0.0031410877127200365, -0.004169350955635309, -0.01214046124368906, -0.01181592047214508, 0.02932785637676716, 0.0009628584375604987, 0.016597924754023552, 0.018598152324557304, -0.006003997754305601, 0.024188196286559105, -0.018810097128152847, -0.01969761587679386, -0.02887747436761856, -0.002487039426341653, -0.025459865108132362, 0.03658696636557579, 0.009279206395149231, -0.019591644406318665, 0.009411672130227089, 0.0047720689326524734, -0.01229279674589634, -0.01393536850810051, 0.016929088160395622, 0.04087884724140167, 0.012994863092899323, -0.010716456919908524, -0.02773827128112316, 0.03144730255007744, 0.004974078852683306, -0.014346010982990265, -0.009921664372086525, -0.0019803589675575495, 0.01736622489988804, 0.00033592418185435236, -0.04278634861111641, 0.002235354855656624, 0.02345963567495346, 0.004258764907717705, 0.018002059310674667, -0.003967341035604477, -0.02704945020377636, -0.010405163280665874, 0.0031857946887612343, 0.004765445366501808, 0.006735869683325291, 0.01386913564056158, 0.03136782348155975, -0.0001004874866339378, -0.0009926632046699524, 0.007841955870389938, -0.01286239828914404, 0.004245518706738949, 0.01722051203250885, -0.0070272935554385185, -0.00037235216586850584, 0.012504740618169308, 0.002872845157980919, -0.026625560596585274, -0.025380386039614677, -0.026347383856773376, 0.00853077694773674, -0.004619733430445194, -0.019101521000266075, -0.028956953436136246, 0.008318832144141197, 0.012763048522174358, 0.021075258031487465, -0.00582185760140419, 0.007391573861241341, 0.00933881662786007, 0.005894713569432497, 0.019128015264868736, 0.009444788098335266, -0.0012153707211837173, -0.0018793540075421333, -0.03308987617492676, -0.020876558497548103, 0.0002570658107288182, -0.009332193061709404, -0.0008966256864368916, 0.035845156759023666, -0.019286973401904106, 0.018147770315408707, 0.014465230517089367, 0.015021584928035736, -0.0019505542004480958, 0.010213088244199753, -0.016452211886644363, -0.017922578379511833, 0.026956724002957344, 0.0050767394714057446, -0.012445131316781044, -0.018319975584745407, -0.022850295528769493, -0.029566295444965363, 0.001484441221691668, 0.0074776760302484035, -0.01106749102473259, -0.0024572345428168774, -0.003407674375921488, 0.00035662189475260675, 0.01229941938072443, -0.00033426834852434695, -0.014981845393776894, -0.012776295654475689, -0.02147265337407589, -0.0017319860635325313, -0.011617222800850868, -0.002039968268945813, 0.017419209703803062, -0.009120248258113861, 0.005722508765757084, -0.004285258240997791, 0.00966998003423214, -0.028903966769576073, 0.02506246790289879, -0.014253285713493824, -0.02626790478825569, -0.020783834159374237, -0.010372047312557697, -0.0057324436493217945, -0.0011830823495984077, 0.007298847660422325, 0.0008626814233139157, -0.01500833872705698, -0.006288798525929451, 0.00015595740114804357, -0.02017449215054512, -0.0008759279735386372, 0.0014645714545622468, 0.0019638007506728172, 0.01459769532084465, 0.007292224559932947, 0.014730161055922508, -0.0015241808723658323, 0.015842871740460396, -0.0027751517482101917, -0.011458263732492924, 0.003596437629312277, -0.002220452530309558, -0.02609569951891899, 0.013922121375799179, -0.006619962397962809, 0.012286173179745674, -0.031394317746162415, 0.01352472510188818, 0.008338701911270618, 0.00835857167840004, 0.023406649008393288, 0.0019836705178022385, 0.0037719544488936663, -0.010855546221137047, -0.006636520382016897, -0.03399064019322395, -0.01902204193174839, 0.001546534476801753, 0.018664386123418808, 0.009020899422466755, 0.018651138991117477, -0.006335161626338959, -0.01887633092701435, 0.015365995466709137, 0.00794130563735962, 0.01670389622449875, -0.012564350850880146, 0.0023562295828014612, -0.016491951420903206, -0.011478133499622345, -0.015365995466709137, 0.00202837772667408, 0.019565150141716003, -0.01321343146264553, -0.020942792296409607, -0.0014198643621057272, 0.021432913839817047, 0.03261300176382065, 0.013233301229774952, -0.03274546563625336, 0.007490922696888447, 0.026771273463964462, 0.013359143398702145, 0.013491609133780003, 0.01286239828914404, -0.005676145665347576, 0.011007880792021751, 0.004775380250066519, 0.043554648756980896, -0.0017651024973019958, 0.0018942563328891993, 0.022890035063028336, 0.03459998220205307, -0.014465230517089367, 0.02654608152806759, 0.01951216533780098, 0.02210848778486252, 0.0028248263988643885, 0.0012857430847361684, 0.027923721820116043, -0.023857032880187035, 0.019737355411052704, -0.011478133499622345, 0.0004950897418893874, 0.04066690057516098, -0.01670389622449875, -0.024506112560629845, 0.001723707071505487, 0.02099577896296978, 0.030573032796382904, 0.0031907621305435896, 0.0025317464023828506, -0.007338587660342455, 0.006162956357002258, 0.021194476634263992, -0.0059212069027125835, -0.00205155904404819, -0.00910700112581253, -0.01670389622449875, 0.0013701898278668523, -0.02295626699924469, 0.004119676537811756, 0.01369693037122488, -0.0033331625163555145, 0.011272812262177467, 0.0036726053804159164, 0.027817750349640846, -0.004414412193000317, 0.002121103461831808, 0.008895057253539562, -0.001083733164705336, -0.0351298451423645, 0.027446847409009933, -0.0066497670486569405, -0.007934682071208954, -0.01688934862613678, -0.035023871809244156, 0.024863770231604576, -0.01573689840734005, 0.012855774722993374, 0.011756311170756817, 0.008464544080197811, 0.025618823245167732, -0.016677403822541237, 0.02343314327299595, 0.034335050731897354, 0.010073999874293804, -0.0014215201372280717, -0.0040501318871974945, -0.022360172122716904, -0.0052721258252859116, -0.0007273182854987681, 0.0017535117221996188, 0.0033828371670097113, 0.020267218351364136, -0.015074571594595909, 0.0013602548278868198, -0.004891287535429001, -0.016929088160395622, -0.002382722683250904, 0.007822086103260517, 0.009729589335620403, -0.01345849223434925, -0.014849379658699036, 0.0299901831895113, 0.01642571948468685, -0.004195843823254108, 0.014200299046933651, 0.02425442822277546, 0.007007423788309097, -0.005967569537460804, -0.022214461117982864, -0.011974879540503025, 0.010246205143630505, 0.04122325778007507, 0.025949986651539803, 0.0027900540735572577, 0.0011052588233724236, 0.012160331010818481, -0.010815806686878204, -0.03128834441304207, -0.0034904652275145054, -0.002035000827163458, 0.000963686325121671, -0.017604662105441093, -0.006295421626418829, 0.016346240416169167, 0.0032420926727354527, 0.01837296225130558, -0.002977161668241024, -0.00532842380926013, -0.00918648112565279, 0.0007658160175196826, -0.011127100326120853, 0.003639488946646452, 0.0020648057106882334, 0.0008601977024227381, 0.007278977893292904, 0.015034832060337067, -0.016849609091877937, 0.0011706636287271976, 0.005401279777288437, -0.002637718804180622, -0.02345963567495346, 0.0031063153874129057, 0.024148456752300262, 0.00524232117459178, 0.01296837069094181, -0.01605481654405594, 0.026956724002957344, -0.007338587660342455, 0.005838416051119566, 0.01402809377759695, 0.007252485025674105, 0.0006850949139334261, 0.03118237294256687, -0.003427544143050909, 0.004374672193080187, 0.01105424389243126, -0.009921664372086525, -0.01304122619330883, -0.002452267101034522, -0.014690421521663666, -0.01034555397927761, 0.012504740618169308, 0.0031145946122705936, 0.00045824775588698685, -0.02572479657828808, 0.025539344176650047, 0.009722965769469738, -0.006076853722333908, -0.0008618535357527435, -0.014359258115291595, -0.026281150057911873, -0.018293483182787895, -0.018637891858816147, -0.01853192038834095, -0.02916889823973179, -0.029301363974809647, -0.029963690787553787, -0.004222337156534195, -0.01000114344060421, -0.012425261549651623, -0.014544709585607052, 0.015087817795574665, -0.01540573500096798, -0.0269169844686985, -0.018002059310674667, 0.005762248300015926, 0.004248830024152994, 0.006341784726828337, -0.0052158283069729805, -0.009550760500133038, -0.008550646714866161, 0.0007562951068393886, -0.00811351090669632, 0.012365652248263359, -0.029301363974809647, -0.012511364184319973, 0.02773827128112316, -0.012332536280155182, 0.0046992129646241665, 0.01271006278693676, 0.001318859402090311, 0.024731304496526718, -0.005099921021610498, -0.004987325053662062, -0.01589585654437542, 0.01752518303692341, -0.010073999874293804, -0.010365423746407032, 0.00233635981567204, 0.00741806672886014, -0.015260023064911366, -0.019432686269283295, -0.01674363575875759, 0.007828709669411182, -0.002980473218485713, 0.0291953906416893, -0.00398058770224452, 0.0015175576554611325, 0.020399684086441994, -0.013133952394127846, 0.0007533974130637944, -0.014451983384788036, 0.0012070916127413511, 0.0018810097826644778, -0.006679571699351072, -0.0008949699113145471, -0.00492109265178442, 0.004278635140508413, 0.015207036398351192, -0.00820623617619276, -0.02047916315495968, 0.007656504400074482, -0.024545852094888687, 0.00918648112565279, 0.023366909474134445, 0.009901794604957104, 0.027658792212605476, -0.011464887298643589, -0.007437936495989561, -0.009047391824424267, -0.0033331625163555145, -0.009146741591393948, 0.019154507666826248, -0.017472196370363235, -0.02330067753791809, -0.020108260214328766, -0.02326093800365925, -0.02018773928284645, 0.0040435087867081165, 0.006235812325030565, 0.006888204719871283, -0.01967112347483635, 0.008663242682814598, 0.007510792464017868, -0.023221198469400406, -0.033195849508047104, -0.024837277829647064, -0.020558642223477364, 0.022095242515206337, -0.01065684761852026, 0.012584220618009567, 0.02065136842429638, 0.00299206399358809, -0.010610484518110752, -0.021035518497228622, 0.0008432255708612502, -0.023711320012807846, -0.013829396106302738, -0.006709376350045204, 0.024863770231604576, 0.01124631892889738, 0.030943935737013817, -0.014942105859518051, 0.018651138991117477, 0.012465001083910465, -0.0038315639831125736, 0.018664386123418808, -0.006225877441465855, -0.025168441236019135, -0.0011209890944883227, 0.0008353604353033006, -0.0066497670486569405, 0.02179057151079178, 0.001345352502539754, 0.006013932637870312, 0.00796117540448904, 0.007901566103100777, -0.01524677686393261, 0.018121277913451195, -0.007596895098686218, -0.013948614709079266, -0.021909790113568306, 0.02230718731880188, -0.011040997691452503, 0.014147313311696053, -0.01752518303692341, -0.007570402231067419, 0.010179972276091576, 0.011352291330695152, 0.016147540882229805, 0.019909560680389404, 0.008418180979788303, -0.02098253183066845, -0.0002527192991692573, 0.008795707486569881, -0.003204008797183633, -0.008391687646508217, -0.002293308498337865, -0.02490350976586342, -0.005020441487431526, 0.020598381757736206, 0.030440567061305046, 0.0051429723389446735, -0.018955809995532036, 0.021075258031487465, 0.005444331094622612, 0.013670437037944794, -0.006285486742854118, -0.0062556820921599865, 0.0033828371670097113, -0.012729932554066181, -0.018823344260454178, -0.026506341993808746, -0.020293710753321648, -0.007358457427471876, 0.0022187966387718916, 0.02096928469836712, -0.022519130259752274, -0.000595680670812726, -0.00974283553659916, 0.0010290911886841059, -0.016465459018945694, 0.008557270281016827, 0.048773787915706635, 0.0076829977333545685, 0.0014604318421334028, 0.01540573500096798, -0.010186594910919666, -0.010782689787447453, 0.020757339894771576, -0.01025945134460926, -0.0048283664509654045, 0.042918816208839417, 0.03210963308811188, -0.00293079880066216, -0.004623045213520527, 0.002109512686729431, 0.009027522057294846, 0.005225763190537691, -0.018624646589159966, 0.01091515552252531, 0.004980701953172684, -0.012266303412616253, -0.01658467762172222, -0.0016682371497154236, -0.0478995181620121, 0.005560238379985094, -0.007987668737769127, -0.011100606992840767, -0.020956039428710938, 0.010153478942811489, -0.03052004612982273, 0.03515633940696716, -0.018624646589159966, 0.00843142718076706, 0.006537171546369791, -0.0006172063294798136, -0.00984880793839693, 0.005590043030679226, -0.01409432664513588, -0.0022717828396707773, 0.018492180854082108, 0.026678547263145447, -0.01572365127503872, 0.00011725264630513266, 0.01821400225162506, 0.0066563901491463184, -0.004917780868709087, 0.004338244441896677, -0.010080622509121895, 0.024492867290973663, -0.02641361579298973, -0.009888547472655773, 0.007795593235641718, 0.02063812129199505, 0.004487268161028624, -0.0029158962424844503, -0.0055999779142439365, -0.018121277913451195, -0.013683684170246124, -9.769328607944772e-05, 0.021273955702781677, -0.006149709690362215, -0.0011648682411760092, -0.0038779268506914377, -0.007835333235561848, -0.004083248320966959, -0.006987554021179676, -0.021525640040636063, -0.016293253749608994, -0.032401055097579956, -0.012153707444667816, 0.003497088560834527, -0.002765216864645481, 0.021101750433444977, 0.0022767502814531326, -0.010709834285080433, 0.013226677663624287, 0.030546538531780243, -0.02312847226858139, 0.0021409732289612293, 0.0011251287069171667, 0.016359485685825348, 0.003041738411411643, -0.008219483308494091, 0.010650224052369595, -0.02361859381198883, 0.01589585654437542, -0.010776066221296787, -0.015418981201946735, -0.003612995846197009, -0.009696473367512226, 0.01499509159475565, -0.010007767006754875, -0.008338701911270618, 0.0008200440788641572, 0.004851548001170158, 0.013339273631572723, 0.011696701869368553, -0.029089419171214104, 0.01835971511900425, 0.008987782523036003, -0.00036821264075115323, 0.011597352102398872, -0.017922578379511833, -0.0028082681819796562, 0.0013056128518655896, -0.00626892875880003, 0.006500743329524994, -0.019618136808276176, -0.018611399456858635, 0.005974193103611469, 0.01589585654437542, 0.006302045192569494, -0.014253285713493824, -0.029592787846922874, -0.009491151198744774, -0.007252485025674105, 0.014478476718068123, -0.00048763855011202395, -0.008153250440955162, -0.011994749307632446, 0.0012410359922796488, -0.005997374653816223, 0.0006660529761575162, -0.00886194035410881, -0.006169579457491636, -0.025989726185798645, -0.005643029231578112, -0.02768528461456299, -0.012120591476559639, 0.0015241808723658323, 0.01899554952979088, 0.006162956357002258, -0.02821514755487442, -0.022187966853380203, 0.0016549905994907022, -0.04739614948630333, -0.028135666623711586, -0.01065684761852026, -0.0033017019741237164, 0.007894942536950111, 0.02408222295343876, -0.013961860910058022, 0.03738175705075264, -0.0009761049877852201, 0.023525869473814964, -0.01822724938392639, 0.005053557921200991, 0.0016922465292736888, -0.02213498204946518, -0.006888204719871283, 0.00759027199819684, -0.01524677686393261, -0.002506909193471074, 0.019644631072878838, 0.003096380503848195, 0.007524039130657911, 0.049118198454380035, 0.008219483308494091, -0.012027865275740623, 0.0008684768108651042, 0.011325797997415066, -0.0061165932565927505, 0.005106544122099876, 0.00607023062184453, 0.005394656676799059, 0.002379411133006215, -0.00021794710482936352, 0.009974650107324123, -0.004023639019578695, -0.015471967868506908, -0.0021724337711930275, 0.009444788098335266, 0.023406649008393288, -0.024161703884601593, 0.0011938450625166297, -0.015670666471123695, -0.012531233951449394, 0.027115684002637863, -0.01625351421535015, -0.034546997398138046, 0.02903643250465393, 0.018598152324557304, -0.012478248216211796, -0.010948271490633488, 0.026135439053177834, -0.004543565679341555, -0.018465688452124596, -0.0010340586304664612, -0.011809296905994415, -0.02214822731912136, -0.01918100193142891, 0.004891287535429001, -0.015935596078634262, -0.00851752981543541, -0.009047391824424267, -0.008868563920259476, -0.008597009815275669, -0.0012716685887426138, 0.004434281960129738, -0.025883754715323448, -0.019710863009095192, -0.02527441270649433, 0.01937969960272312, -0.01098801102489233, -0.0009496118873357773, 0.01278291828930378, 0.008252599276602268, 0.013233301229774952, 0.021287202835083008, -0.0034573490265756845, -0.007822086103260517, 0.022029008716344833, 0.01165696233510971, 0.00013018872414249927, 0.030546538531780243, 0.23780202865600586, -0.01345186959952116, 0.01115359365940094, 0.03115588054060936, 0.0029904081020504236, 0.006788855884224176, -0.004944273736327887, 0.002965570893138647, -0.009318945929408073, 0.012253056280314922, 0.026824258267879486, 0.0044442168436944485, 0.0031212177127599716, -0.002291652839630842, -0.0028397287242114544, -0.007212745025753975, -0.02017449215054512, -0.01653169095516205, -0.039289262145757675, -0.0269169844686985, -0.000637904042378068, -0.020571889355778694, -0.0028745008166879416, -0.013484985567629337, -0.0002912170602940023, -0.0021310383453965187, -0.020598381757736206, 0.007431313395500183, 0.019392946735024452, 0.031579770147800446, -0.014822887256741524, 0.0032056644558906555, 0.022187966853380203, 0.002760249422863126, -0.02134018763899803, -0.004040197003632784, 0.031738728284835815, 0.01533950213342905, 0.03822953626513481, 0.009371932595968246, 0.04005755856633186, -0.012855774722993374, -0.0048879762180149555, -0.009299076162278652, 0.002063149819150567, 0.017299991101026535, -0.005765560083091259, -0.01918100193142891, -0.018280236050486565, 0.01039853971451521, 0.010113739408552647, -0.006302045192569494, 0.02181706391274929, 0.010451526381075382, 0.01296837069094181, -0.006914698053151369, 0.025181686505675316, -0.0019720797426998615, -0.002679114229977131, 0.0030516735278069973, 0.002962259342893958, 0.016187282279133797, -0.014584449119865894, 0.010391917079687119, -0.013564464636147022, 0.02298276126384735, -0.01752518303692341, -0.01642571948468685, 0.0002078052202705294, -0.005510563962161541, 0.0007728532655164599, -0.010590614750981331, 0.0033017019741237164, 0.0023032433819025755, -0.027287889271974564, -0.01951216533780098, 0.026360629126429558, 0.01983008161187172, 0.02507571503520012, 0.03279845044016838, -0.013829396106302738, -0.009285829961299896, -0.008597009815275669, -0.039633672684431076, -0.025949986651539803, -0.04792600870132446, 0.008895057253539562, -0.015657419338822365, -0.0010920122731477022, -0.028294626623392105, -0.00786182563751936, -0.0054840706288814545, -0.007411443628370762, -0.009782575070858002, 0.00878908485174179, 0.006570287514477968, -0.0034441023599356413, 0.026360629126429558, 0.00984218530356884, -0.007808839902281761, -0.015207036398351192, 0.03687838837504387, 0.03301039710640907, -0.009054015390574932, -0.003454037243500352, 0.008325455710291862, -0.019233986735343933, -0.001407445641234517, 0.0043713608756661415, 0.005510563962161541, -0.003662670496851206, -0.008868563920259476, 0.007802216801792383, -0.02392326481640339, -0.00488135265186429, 0.007298847660422325, 0.016849609091877937, -0.016942335292696953, 0.013657190836966038, -0.007318717427551746, -0.023578854277729988, 0.012504740618169308, 0.008146626874804497, 0.00389448506757617, -0.007060409989207983, -0.008974536322057247, -0.02654608152806759, -0.0035004003439098597, 0.013670437037944794, -0.016611170023679733, 0.007265731226652861, 0.00504362303763628, 0.01533950213342905, -0.002016786951571703, -0.006709376350045204, 0.015273269265890121, 0.010643601417541504, 0.010219711810350418, -0.010113739408552647, 0.012239810079336166, 0.01639922522008419, -0.01626676134765148, 0.0041097416542470455, -0.011451640166342258, -0.013239924795925617, -0.036825403571128845, 0.023843785747885704, -0.007716114167124033, -0.000686336774379015, -0.015207036398351192, -0.030626017600297928, -0.007530662231147289, -0.006593469064682722, 0.0004379639867693186, 0.018796851858496666, -0.017127785831689835, -0.014981845393776894, -0.046495381742715836, 0.009650110267102718, -0.006325226742774248, -0.0393422469496727, -0.0024390206672251225, 0.02773827128112316, -0.02752632647752762, -0.011365537531673908, -0.007914812304079533, -0.17188720405101776, 0.0036726053804159164, -0.0019174377666786313, -0.01442549005150795, 0.0003435823309700936, -0.008888433687388897, 0.019777094945311546, -0.012438508681952953, -0.0012054358376190066, 0.0006213458837009966, 0.010226334445178509, -0.02295626699924469, -0.035500746220350266, -0.013140575028955936, 0.0002916310331784189, 0.019724110141396523, -0.023552361875772476, -0.020598381757736206, 0.011266188696026802, 0.016478706151247025, 0.021234216168522835, -0.015604433603584766, 0.02001553401350975, -0.01768414117395878, -0.0018578283488750458, -0.016611170023679733, 0.0055436803959310055, 0.02900994010269642, -0.001970424083992839, 0.007153135724365711, 0.0017949072644114494, -0.011213202960789204, 0.030228622257709503, -0.003493777010589838, 0.011941762641072273, 0.019445931538939476, 0.054363831877708435, -0.015644172206521034, -0.005126413889229298, 0.016611170023679733, 0.02200251631438732, 0.009650110267102718, -0.019154507666826248, -0.0025085650850087404, 0.004139546304941177, 0.017273498699069023, 0.01967112347483635, -0.006527236197143793, 0.03150029107928276, -0.010577368550002575, 0.009895171038806438, -0.023499375209212303, 0.011127100326120853, -0.004252141807228327, 0.007762476801872253, 0.00545095419511199, -0.007822086103260517, 0.0057390667498111725, 0.0036328656133264303, 0.01838620752096176, 0.004480644594877958, -0.021936282515525818, 0.0022999318316578865, -0.014041340909898281, -0.021101750433444977, -0.018425947055220604, -0.0370638407766819, 0.014081080444157124, 0.008438050746917725, 0.004907845985144377, 0.0021807129960507154, -0.0012708406429737806, 0.013504855334758759, 0.010093869641423225, 0.01336576696485281, 0.01385588850826025, -0.026161931455135345, 0.02506246790289879, -0.007252485025674105, 0.011299305595457554, 0.0012393801007419825, 0.03441452980041504, 0.012412015348672867, 0.019949300214648247, -0.008828824386000633, 0.007272354792803526, -0.0012327568838372827, 0.0023562295828014612, -0.016690650954842567, 0.0033795253839343786, 0.03118237294256687, -0.029301363974809647, -0.010206464678049088, -0.010391917079687119, 0.0059212069027125835, 0.017472196370363235, 0.01443873718380928, 0.0022237643133848906, -0.007113396190106869, 0.0008494348730891943, -0.009265960194170475, -0.015710406005382538, -0.014518216252326965, 0.024824030697345734, 0.023684827610850334, -0.000574568985030055, -0.010948271490633488, 0.012690193019807339, 0.04432294890284538, -0.005583419930189848, -0.022744322195649147, -0.003162613371387124, 0.03036108799278736, 0.014081080444157124, 0.011544366367161274, 0.021353434771299362, -0.001900879549793899, -0.027115684002637863, 0.0026012908201664686, 0.006206007674336433, 0.039925094693899155, -0.00794130563735962, -0.028480077162384987, 0.028930461034178734, 0.005444331094622612, -0.02392326481640339, -0.09537514299154282, -0.03083796240389347, 0.02263835072517395, 0.03759370371699333, 0.006013932637870312, 0.030149143189191818, 0.011206579394638538, 0.011286058463156223, -0.013425376266241074, 0.0025201556272804737, -0.009040769189596176, -0.03065251186490059, -0.022890035063028336, -0.010782689787447453, 0.007928058505058289, -0.013206807896494865, 0.02296951413154602, 0.007086902856826782, -0.02247939072549343, 0.03722279891371727, -0.014743407256901264, -0.009371932595968246, 0.03258650749921799, -0.029089419171214104, -0.010723080486059189, 0.006480873562395573, -0.02834761142730713, 0.015193790197372437, 0.007914812304079533, -0.010557498782873154, -0.001137547311373055, -0.012259679846465588, 0.016968827694654465, -0.016346240416169167, -0.015313008800148964, -0.0007206950103864074, -0.021578626707196236, -0.02179057151079178, 0.014703667722642422, -0.012769672088325024, 0.007451183162629604, 0.011802674271166325, -0.019750602543354034, -0.04034898430109024, -0.00870298221707344, -0.0076763746328651905, 0.0016897626919671893, 0.012279549613595009, -0.006285486742854118, -0.019565150141716003, -0.039925094693899155, 0.005023753270506859, -0.015776637941598892, 0.009239466860890388, 0.01000114344060421, 0.01817426271736622, 0.020876558497548103, 0.0036692938301712275, -0.012604090385138988, -0.002904305700212717, -0.028453584760427475, -0.006222565658390522, -0.020598381757736206, -0.010597238317131996, -0.015710406005382538, 0.008649995550513268, -0.026863999664783478, 0.0036957869306206703, -0.0025416812859475613, 0.0291953906416893, -0.007411443628370762, 0.012200070545077324, -0.010550875216722488, 0.012484870851039886, -0.031129388138651848, 9.255766599380877e-06, -0.026108944788575172, -0.036825403571128845, 0.024347154423594475, -0.0008966256864368916, -0.028135666623711586, -0.013511478900909424, 0.005195958539843559, -0.02179057151079178, -0.009140118025243282, 0.024810783565044403, -0.01172981783747673, 0.005441019311547279, 0.011146970093250275, -0.043210238218307495, -0.005162842106074095, 0.014743407256901264, 0.019724110141396523, -0.016796622425317764, -0.020200984552502632, -0.0018495492404326797, 0.008385065011680126, -0.0042322720400989056, 0.007106773089617491, 0.005990751087665558, -0.03277195990085602, -0.02638712339103222, -0.06019231304526329, 0.01674363575875759, 0.0005691875703632832, -0.03867992013692856, -0.015617679804563522, -0.00966998003423214, -0.01588261127471924, -0.011252942495048046, -0.005652964115142822, 0.025658562779426575, 0.004709147848188877, -0.002260192297399044, -0.003351376624777913, 0.013292910531163216, -0.013345897197723389, -0.002429085783660412, 0.018319975584745407, -0.004288570024073124, 0.008815577253699303, 0.01822724938392639, 0.005195958539843559, -0.022081995382905006, 0.002498629968613386, 0.011358914896845818, -0.009040769189596176, 0.018889576196670532, -0.0280561875551939, 0.0019836705178022385, -0.020386436954140663, -0.022360172122716904, -0.0010473051806911826, -0.038441482931375504, -0.009749459102749825, -0.0019373076502233744, -0.014120819978415966, 0.011392030864953995, 0.001700525521300733, 0.037805646657943726, 0.023737814277410507, 0.022505884990096092, -0.00022746805916540325, -0.02916889823973179, 0.017127785831689835, -0.02017449215054512, -0.014120819978415966, 0.02673153392970562, -0.025870507583022118, 0.0011011193273589015, 0.03165924921631813, 0.012604090385138988, 0.008265845477581024, -0.008126757107675076, -0.028612542897462845, -0.0032520275563001633, -0.000890830357093364, -0.010623731650412083, 0.016280006617307663, -0.0013544595567509532, -0.0010572400642558932, -0.00908713135868311, 0.04792600870132446, 0.00925933662801981, 0.017008567228913307, -0.005838416051119566, 0.0017485442804172635, 0.01655818521976471, -0.011994749307632446, -0.003064919961616397, 0.007285601459443569, -0.015313008800148964, -0.018651138991117477, 0.0024125275667756796, 0.01116021629422903, 0.019313465803861618, 0.011584105901420116, 0.022837048396468163, 0.020373189821839333, -0.00018276096670888364, 0.00019424820493441075, 0.02655932866036892, 0.016677403822541237, 0.0011408589780330658, -0.010431656613945961, 0.0076763746328651905, 0.008159873075783253, 0.02014799974858761, 0.008100263774394989, 0.001530804205685854, -0.010769443586468697, 0.0013552873861044645, -0.011610599234700203, 0.005507252179086208, -0.0032139436807483435, 0.007437936495989561, -0.01998903974890709, -0.02363184094429016, 0.0039276015013456345, 0.02016124501824379, 0.021843556314706802, 0.030467059463262558, 0.040613915771245956, 0.010974764823913574, -0.008656619116663933, -0.03645449876785278, -0.018783604726195335, 0.0023164900485426188, -0.019737355411052704, -0.030890949070453644, 0.019763849675655365, -0.001233584713190794, -0.005553615279495716, -0.0006155504961498082, 0.0005298618925735354, 0.009206350892782211, -0.01376316323876381, 0.00829233881086111, -0.0034772187937051058, -0.003008622210472822, -0.027181915938854218, 0.029884211719036102, -0.0050336881540715694, 0.012405391782522202, 0.03576567769050598, 0.0024439881090074778, 0.018280236050486565, -0.00813338067382574, -0.009159987792372704, -0.01190202310681343, 0.011279435828328133, 0.002821514615789056, -0.0023198015987873077, 0.0071597592905163765, -0.026440110057592392, -0.003427544143050909, -0.006861711852252483, -0.004033573903143406, -0.012875644490122795, 0.022823801264166832, 0.011537742801010609, 0.06527898460626602, 0.01461094245314598, -0.018465688452124596, 0.01369693037122488, 0.003261962439864874, 0.018916070461273193, 0.02115473710000515, 0.009855431504547596, -0.012431885115802288, -0.01238552201539278, 0.015021584928035736, 0.0021923035383224487, 0.0026360629126429558, -0.042229995131492615, -0.034043628722429276, -0.00733196409419179, -0.0023396715987473726, 0.016147540882229805, -0.019075028598308563, 0.010636977851390839, 0.009299076162278652, 0.015604433603584766, 0.027844242751598358, 0.015021584928035736, -0.021764077246189117, 0.014134066179394722, 0.04328971728682518, -0.028480077162384987, -0.01107411365956068, -0.011988125741481781, 0.016677403822541237, 0.00943154189735651, -0.0303345937281847, -0.01442549005150795, 0.005878155585378408, 0.007603518199175596, 0.007365080527961254, -0.003864680416882038, 0.008643371984362602, -0.0003475148987490684, 0.006653078831732273, 0.034520503133535385, -0.02066461369395256, -0.006457692012190819, 0.00759027199819684, 0.0002748658589553088, -0.02344639040529728, 0.00034999861964024603, -0.005858285818248987]\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# Set up the OpenAI client with your API key\n",
        "client = openai.OpenAI(api_key=\"API KEY HERE",
        "\n",
        "# Generate an embedding using the new API format\n",
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=\"This is a test text for embedding.\"\n",
        ")\n",
        "\n",
        "# Print the embedding output\n",
        "print(response.data[0].embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwiUExwwF-wm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"API KEY HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w17eGydF_2q"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI(api_key=os.getenv(\"API KEY HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkudmpHtGFv0",
        "outputId": "214e0d97-c816-48df-ba20-4b0a5e31f4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  \\\n",
            "0  Thursday, August 01, 2019 Each day, Google usu...   \n",
            "1  Omi Sido â€” by Table of Contents Understanding ...   \n",
            "2  Error fetching URL: 403 Client Error: Forbidde...   \n",
            "3  We gebruikencookiesen gegevens voor het volgen...   \n",
            "4  Pricing Features Rank Tracker SEO Reporting Co...   \n",
            "\n",
            "                                              Source  \n",
            "0  https://developers.google.com/search/blog/2019...  \n",
            "1  https://omisido.com/how-to-track-ai-traffic-in...  \n",
            "2  https://www.amnavigator.com/blog/2010/06/30/ho...  \n",
            "3  https://www.google.com/search?q=The+Art+of+SEO...  \n",
            "4  https://www.advancedwebranking.com/blog/gsc-bu...  \n",
            "Column Names: Index(['Text', 'Source'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/content/drive/MyDrive/SEO/Custom GPT project/Archive/extracted_text (2).csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows to check data\n",
        "print(df.head())\n",
        "\n",
        "# Print column names\n",
        "print(\"Column Names:\", df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLh2Jn--GikI",
        "outputId": "91cecb0b-8ce6-45f0-b6e3-88fd7239a887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Text', 'Source'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "aQqbQwE1GlRF",
        "outputId": "a40fbc46-e6c9-408e-e493-883c670db38e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens, however you requested 8608 tokens (8608 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-f36c3978cebb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Apply embeddings to the correct text column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Display the first few rows with embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-f36c3978cebb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Apply embeddings to the correct text column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Display the first few rows with embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-f36c3978cebb>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define a function to generate embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-ada-002\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     response = client.embeddings.create(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/embeddings.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;34m\"/embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaybe_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_create_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingCreateParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens, however you requested 8608 tokens (8608 in your prompt; 0 for the completion). Please reduce your prompt; or completion length.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# Set up OpenAI client\n",
        "client = openai.OpenAI(api_key=\"API KEY HERE")  # Replace with your API key\n",
        "\n",
        "# Define a function to generate embeddings\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    response = client.embeddings.create(\n",
        "        model=model,\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# Apply embeddings to the correct text column\n",
        "df[\"embedding\"] = df[\"Text\"].apply(lambda x: get_embedding(str(x)))\n",
        "\n",
        "# Display the first few rows with embeddings\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzM9zPqCHqXK",
        "outputId": "ece7e0ee-7852-41c5-dc4b-729c072824e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… File saved successfully at: /content/embedded_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the DataFrame with embeddings to a new CSV file\n",
        "output_file_path = \"/content/embedded_data.csv\"\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(f\"âœ… File saved successfully at: {output_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aowdsErHJEp7",
        "outputId": "637a8690-aa71-4d88-9d26-f81d18ab4f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "yrf4USZCJGjm",
        "outputId": "9d31b37d-f736-4f39-cc18-d0118326b12d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'embedding'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'embedding'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-81712e0a5596>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convert embeddings from string format back to a list of numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Converts string list back to float list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert to NumPy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'embedding'"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the saved CSV file with embeddings\n",
        "file_path = \"/content/embedded_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert embeddings from string format back to a list of numbers\n",
        "df[\"embedding\"] = df[\"embedding\"].apply(eval)  # Converts string list back to float list\n",
        "embeddings = np.array(df[\"embedding\"].tolist()).astype(\"float32\")  # Convert to NumPy array\n",
        "\n",
        "# Get the embedding dimension (should be 1536 for text-embedding-ada-002)\n",
        "embedding_dim = embeddings.shape[1]\n",
        "\n",
        "# Create a FAISS index\n",
        "index = faiss.IndexFlatL2(embedding_dim)  # L2 distance for similarity search\n",
        "index.add(embeddings)  # Add embeddings to the FAISS index\n",
        "\n",
        "print(\"âœ… FAISS index is ready! Now you can search for similar text.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "mADQrQBkJQF6",
        "outputId": "c9a2c6aa-3b6b-4ba9-e5a2-9bb8eb18970c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "positional indexers are out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \"\"\"\n\u001b[0;32m-> 4153\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4133\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   4134\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-69ff3a52b54b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Example Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"what is duplicate content?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_similar_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸ” Top Matches:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-69ff3a52b54b>\u001b[0m in \u001b[0;36msearch_similar_text\u001b[0;34m(query, top_k)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Retrieve matching text from the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m  \u001b[0;31m# Replace YOUR_TEXT_COLUMN with actual column name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0;31m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ],
      "source": [
        "def search_similar_text(query, top_k=3):\n",
        "    # Convert the query into an embedding using OpenAI\n",
        "    query_embedding = client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=query\n",
        "    ).data[0].embedding\n",
        "\n",
        "    # Convert query embedding to the correct format\n",
        "    query_embedding = np.array(query_embedding).astype(\"float32\").reshape(1, -1)\n",
        "\n",
        "    # Search FAISS index for the most similar embeddings\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve matching text from the DataFrame\n",
        "    results = df.iloc[indices[0]][\"Text\"].values  # Replace YOUR_TEXT_COLUMN with actual column name\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example Search\n",
        "query = \"what is duplicate content?\"\n",
        "results = search_similar_text(query)\n",
        "\n",
        "print(\"\\nðŸ” Top Matches:\")\n",
        "for i, res in enumerate(results, 1):\n",
        "    print(f\"{i}. {res}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "vqcCANwDJ8w1",
        "outputId": "0d9c61fe-67a6-4e5f-e31f-5c1460672bd5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "positional indexers are out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \"\"\"\n\u001b[0;32m-> 4153\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4133\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   4134\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-3c69de54a0bc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Example Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is duplicate content?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_similar_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nðŸ” Top Matches:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-3c69de54a0bc>\u001b[0m in \u001b[0;36msearch_similar_text\u001b[0;34m(query, top_k)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Retrieve matching text and their sources from the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Source\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Replace with actual column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0;31m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ],
      "source": [
        "def search_similar_text(query, top_k=3):\n",
        "    # Convert the query into an embedding using OpenAI\n",
        "    query_embedding = client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=query\n",
        "    ).data[0].embedding\n",
        "\n",
        "    # Convert query embedding to the correct format\n",
        "    query_embedding = np.array(query_embedding).astype(\"float32\").reshape(1, -1)\n",
        "\n",
        "    # Search FAISS index for the most similar embeddings\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve matching text and their sources from the DataFrame\n",
        "    results = df.iloc[indices[0]][[\"Text\", \"Source\"]]  # Replace with actual column names\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example Search\n",
        "query = \"What is duplicate content?\"\n",
        "results = search_similar_text(query)\n",
        "\n",
        "print(\"\\nðŸ” Top Matches:\")\n",
        "for i, row in results.iterrows():\n",
        "    print(f\"{i+1}. {row['Text']} (Source: {row['Source']})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxuG8XV5KtKe",
        "outputId": "6d5c610d-6cdd-4e98-8680-34a2632df929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¤– Ask me anything! Type 'exit' to quit.\n",
            "\n",
            "You: YouTube Content Module\n",
            "\n",
            "ðŸ” Top Matches:\n",
            "12. #WTSFest Hubs Initiatives Speaker line-ups live for WTSFestLondon&PortlandEarly birds live forBerlin,Philadelphia, &Melbourne Author:Emina Demiri-Watson Last updated:03/07/2024 May was eventful for SEOs in many ways! Google launched AI Overviews, and of course there was the infamous Google API leak. Rand Fishkin received an email on May 5th from an anonymous source claiming to have access toa massive leak of API documentationfrom inside GoogleÃ¢Â€Â™s Search division. Rand meticulously examined the documents, cross-referencing them with known facts and consulting with SEO experts and former Google employees. Mic King provided further analysis bydigging deeper into the leaked documentationand shedding more light on the potential implications for search engine optimisation. Since then, weÃ¢Â€Â™ve had confirmation (of a kind) from aGoogle spokesman emphasising that it Ã¢Â€Âœlacks contextÃ¢Â€Â.And, the originalanonymous source revealed himself to be Erfan Azimi. The usual caveats apply: the leaks do not tell us what factors Google is using to rank web pages. But that doesn't mean we shouldnÃ¢Â€Â™t be digging deep into the documentation and seeing what we can learn from it. If you havenÃ¢Â€Â™t done so already, IÃ¢Â€Â™d recommend checking outDr Marie HaynesÃ¢Â€Â™ series of articles about the leak. She starts off by explaining what the documents which have been leaked actually are: Ã¢Â€ÂœThese documents are not code that is used in GoogleÃ¢Â€Â™s systems. They are documents to help developers who are building with Google's AI on the Cloud PlatformÃ¢Â€Â¦. These arenÃ¢Â€Â™t ranking algorithms. Yet, we may be able to learn about ranking by studying them.Ã¢Â€Â I tend to agree. Just because itÃ¢Â€Â™s not an actual ranking document, doesnÃ¢Â€Â™t mean it is not useful. This is not an article about Ã¢Â€Â˜the truthÃ¢Â€Â™ or one that claims to know the secrets of the algorithm. Instead, IÃ¢Â€Â™ll be digging deeper into what this documentation might teach us about how to optimise video content. After all,YouTube is the second-most visited site on the internetand itÃ¢Â€Â™sforecasted to grow by 24.9% (232.5 million users)between 2024 and 2029. At the same time, GoogleÃ¢Â€Â™s SERPs have become increasingly diverse as well, withvideos being featured 24.6%of the time, sometimes appearing above the Ã¢Â€Âœ10 blue linksÃ¢Â€Â. From a personal point of view, I also wanted to see if the document is useful to help our recently launched video series Ã¢Â€ÂœSEOÃ¢Â€Â™s Getting CoffeeÃ¢Â€Â become more visible in search. Navboost is Google's advanced web search system that employs click data to either boost or demote rankings. The clue is in the name. I first heard about NavBoost in 2020 during theDOJ Antitrust Trialwhere it was mentioned together with another supposed serving system called Glue. During the trial, Pandu Nayak, a VP of Search at Google, testified that Navboost has been around since 2005. Previously it tracked a rolling 18 months of click data, which has now been reduced to 13 months of data. With this new leak exploding, it was time to dig deeper into it. And, what a rabbit hole it turned out to be. Unsurprisingly, NavBoost is mentioned in reference to video content in the leaked documentation Ã¢Â€Â“ YouTube in particular has always tracked user behaviour, and the algorithm is openly based on this. Elements such as: previous videos watched; matching based on similarity of videos - e.g. what you would likely watch based on previous behaviour; and time spent watching videos on a specific topic or a channel are allpart of the personal recommendation algorithmon YouTube. In fact, YouTube specifically notes that theypay attention to the users and not the video. But how relevant is this when we are talking about video content in the Google SERPs? Two interesting places Navboost pops up in relation to video are both connected to anchors: The YouTube attributes refer to three types of queries: LetÃ¢Â€Â™s start with NavBoost queries. To help me understand what these might be, I usedMic KingÃ¢Â€Â™s article on the leak. To understand NavBoost, as Mic points out, you need to look back to the Panda update. Panda essentially creates a \"modification factor\" to adjust how important specific resources (like videos or web pages) are. The Panda modification factor is calculated using: The modification factor (M) is calculated using this formula:M=IL/RQ IL is the number of different websites linking to your video, and RQ is the number of search queries that are related to your video. I suspect that Reference Queries are likely what the documentation on YouTube refers to as NavBoost queries. They are search terms people have used in the past that are recognised as being related to your video. For example, imagine you have a YouTube video titled \"How to Bake a Chocolate Cake.\" In this example, the system would calculate the modification factor (M) as follows: M=10/50 =0.2 This factor helps the system understand how well-linked your video is compared to how often it is searched for. A higher modification factor would mean more independent links per reference query, potentially boosting the video's visibility in search results. If we consider that something like this is indeed part of how video search works, then NavBoost queries are the search terms and navigation patterns that help the system understand which videos are related to which search queries. For example, if people often search for \"chocolate cake recipe\" and your video frequently comes up as a top result, this query would be considered a NavBoost query. The second term I found interesting is Ã¢Â€Â˜anchor queriesÃ¢Â€Â™. IÃ¢Â€Â™ve never considered videos to have anchors and the only thing that comes to mind which seems plausible here are YouTube video chapters. YouTube video chapters allow users to skip to different sections of the video: Source: Example of chapters in our SEOs Getting Coffee podcast Applied to our cake-baking example video - let's say it has the has the following chapters: 00:00 Introduction 00:45 Ingredients 02:30 Preparation 05:00 Cooking 07:45 Serving Tips 09:00 Conclusion The user might want to skip the intro and go straight to the cooking chapter. YouÃ¢Â€Â™ll notice I added timestamps here. YouTube can automatically create chapters such as these or you can add these to your YouTube description manually and add the timestamps to tell YouTube how to make the sections. If we go with the logic that anchors are video chapters, then anchor queries are those that are related to your video chapters. Now that we know the main terms, let's look at the features themselves and what YouTube content creators can do to optimise their videos. Anchor Text Anchor text, is the chapter text (i.e. the names you give your video chapters). This is crucial because it identifies specific segments of a video that are particularly relevant to certain queries. NavBoost Text NavBoost Text refers to the NavBoost query text. Essentially it's the NavBoost query user interaction data + common navigation patterns) that enhances the chapters. This helps surface the most relevant parts of a video based on how users typically interact with the content. Source This is how the NavBoost query was generated. Yes, thatÃ¢Â€Â™s likely the most murky part. My hunch is that this has to do with the reliability and accuracy of the NavBoost query. Possibly, there is some difference between the different ways they are generated that provides deeper context. Which in turn builds more or less trust? The second interesting mention of NavBoost is related to rank embedding. Rank embedding is a concept straight out of machine learning. The Rank part, as the name itself suggests, relates to sorting documents (in this case videos) based on a predicted relevance score to the query. ThatÃ¢Â€Â™s the simple explanation. Behind this is of course a mathematical equation thatÃ¢Â€Â™s not that simple. Typically, ranking models predict a relevance score s = f(x) for each input x = (q, d) where q is a query and d is a document. Then the relevance score is what determines the sorting (the ranking). The higher the score, the better the rank. Source: Learning to Rank: A Complete Guide to Ranking using Machine Learning The second part that needs explaining is the concept of Embedding. This relates to one of the approaches used to implement the scoring model. Specifically,the Vector Space Model. I first heard of the concept of embedding in theexcellent intro to LLMÃ¢Â€Â™s by Britney Muller. Computers don't understand words like we do. Instead, every word is tokenized, translated into a string of numbers. These tokens are then converted into dense numerical vectors. This allows the computer to understand the relationships between the tokens (words). HereÃ¢Â€Â™s agreat example from Britney: Ã¢Â€ÂœImagine every word or token being transformed into a multi-dimensional vector that captures its relationship with other words. This is the crux of embeddings. When we perform operations on these vectors, like the classic example of the vector representation for the word Ã¢Â€ÂœKing,Ã¢Â€Â. Ã¢Â€Â”If you subtract the vector Ã¢Â€ÂœmanÃ¢Â€Â from the vector for Ã¢Â€ÂœKingÃ¢Â€Â and add the vector for Ã¢Â€ÂœWoman,Ã¢Â€Â it yields a strikingly similar vector for Ã¢Â€ÂœQueenÃ¢Â€Â. Similarly, if you subtract the vector for Ã¢Â€ÂœstateÃ¢Â€Â from that of Ã¢Â€ÂœCaliforniaÃ¢Â€Â and add Ã¢Â€ÂœcountryÃ¢Â€Â, the closest vector might correspond to Ã¢Â€ÂœAmericaÃ¢Â€Â. Pretty wild, right!? Keep in mind that these relationships arenÃ¢Â€Â™t always universally valid and are heavily influenced by the specific training data and algorithms used.Ã¢Â€Â LetÃ¢Â€Â™s now put the two terms back together again: Rank Embedding. RankEmbed is an approach used in machine learning that basically relates to how documents are represented in a vector space. The distance between vectors represents the similarity or relevance between the items. In the context of this particular model from the leak, rank embedding (rankembed) similarities measure how closely related different elements (such as video anchors, NavBoost queries, and original query candidates) are to each other within the context of search and recommendation algorithms. Each attribute is a clue to how this is done: anchorReSimilarity -This attribute represents the RankEmbed similarity between the rankembed neighbour (a related or similar item in the rank embedding space) and the video anchor (specific segments or points within the video). High anchorReSimilarity means that your video chapters (anchors) closely match, while low anchorReSimilarity is the opposite. navQueryReSimilarity -This is where the user aspects come into play. Coming back to what we said about NavBoost queries being those which are enhanced by user data, this measures the RankEmbed similarity between the RankEmbed neighbour and the top NavBoost query of the video. reSimilarity -This represents the RankEmbed similarity between the rankembed neighbour and the original query candidate, i.e. the initial query that the user searched for. Well we can't know exactly, but if we consider that NavBoost is part of the equation when it comes to your video chapters then there are a few things creators can do. DonÃ¢Â€Â™t rely on YouTube to automatically set your chapters. Instead, think about how to break down your video into chapters in a way that will bring you more visibility. Create clear, concise segments that include relevant keywords and phrases. Check which keywords are popular and add those to your video chapters. Make sure those keywords are included in spoken content, on-screen text, and subtitles. Then use timestamps in video descriptions to highlight key segments, making it easier for YouTube to identify and use these optimised anchors in search results. This one is a no-brainer. NavBoost is all about user behaviours and if your content is flat to start with it simply won't work. Create content that keeps viewers engaged. Higher engagement rates signal to YouTube that the content is valuable. Go beyond simply thinking about an engaging topic, and guide your viewers to engage. For example, you could include compelling hooks and clear calls to action at strategic points in the video. This will not only get you visibility of YouTube, something we already know, but it should boost your videos in search as well. After your video has been up for a while, use data to refine this engagement. YouTube Analytics lets you analyse user retention and behaviours. This will help you understand which chapters are most engaging. Those are the ones you should optimise even further. Encourage user interaction through comments, likes, and shares. This will provide additional data for algorithms to understand and enhance the relevance of your content. Make sure your video's metadata is comprehensive and accurate. This includes titles, descriptions, tags, and closed captions. Interacting with your audience through comments and community posts can help generate more data points for use in NavBoost queries. Pay attention to your transcripts and subtitles. Even when using auto-creation, make sure you check the most important chapters and the keywords connected to them. You donÃ¢Â€Â™t want those to be misspelt. Our initial video \"How to Bake the Perfect Chocolate Cake\" had the following video chapters. Now letÃ¢Â€Â™s optimise it: Those chapters are not optimised currently. We can add some keywords into them that will help the system understand the video better and how it relates to other terms in this space. Example: Rather than simply using Ingredients we can use something like: \"00:45 Ingredients: Best Chocolate for BakingÃ¢Â€Â WeÃ¢Â€Â™ve optimised the chapters in the description. Now let's look at how we can push this further with NavBoost queries. There are 3 ways we can do this: Step 1:Go to YouTube Studio Example of YouTube Studio Dashboard Vixen Digital Step 2: Navigate to the Analytics section and click on Advanced Mode in the right corner Step 3: Check the Traffic Source and choose YouTube Search. Digging into the rest of the sources can also be useful but unfortunately, Google Search thatÃ¢Â€Â™s listed under External wonÃ¢Â€Â™t give you a query breakdown. Step 4: Check the search terms that led viewers to your videos. Example: one ofour videos.Ã‚Â This is for a GA4 tutorial. The next step for us is to review, combine with other keyword research and optimise into chapters. Applying it to our delicious cake-baking video example, letÃ¢Â€Â™s say we noticed that the search \"easy chocolate cake tutorial,\" is popular. We can now make sure one of our video chapters includes this phrase and we can add it into the description. We now know that engaged users help our rankings. LetÃ¢Â€Â™s make sure our baking video actually engages people! WeÃ¢Â€Â™ll edit our video and ask viewers to comment on their favourite cooking chocolate brands during the \"Ingredients\" segment. Using YouTube Analytics, we know the Cooking chapter is the most engaging one for viewers. So weÃ¢Â€Â™ll add a subscribe CTA to it. Or better yet, letÃ¢Â€Â™sadd that Ã¢Â€ÂœSubscribe to all of our videosÃ¢Â€Âjust likePreppy Kitchenhas done. The basic elements can be tweaked as well; for example,our title could be more comprehensive: \"How to Bake the Perfect Chocolate Cake - Easy Chocolate Cake Recipe Tutorial.\" We could also incorporate user navigation insights into the description. For example we might mention a phrase like: \"cooking chocolate cake\" within the video description. I started digging into this because I understand the importance of a video strategy in todayÃ¢Â€Â™s marketing and the prominence of YouTube in user journeys. And, I wanted more viewers to visit ourSEOÃ¢Â€Â™s Getting Coffee podcast. Will this leak completely change the strategies we employ in YouTube or Google Video Search? No. But there is no doubt that the leak hides a lot of ideas for optimising our video content. Useful ideas which will help our viewers better understand, engage with, and enjoy our videos. Emina Demiri-Watson - Head of Digital Marketing, Vixen Digital Emina has over 10 years of digital marketing experience both in-house and agency side. She is the Head of Digital Marketing at a Brighton-based digital marketing agency Vixen Digital, and co-hoststhe SEO Getting Coffee podcast. Subscribe to the WTSNewsletter (Source: https://www.womenintechseo.com/knowledge/digging-into-the-video-content-modules-of-googles-api-leak/)\n",
            "20.     YouTube is thesecond-most popular social media platformand boasts its own search engine that requires unique optimization techniques. Its search engine has also evolved in the wake of various technological advances, algorithm updates, and regulations. This checklist covers how video optimization on YouTube can help improve your contentâ€™s visibility and target the proper keywords for search performance. YouTube SEO is the optimization of video content on your YouTube channel, and it helps to increase the visibility of your content on the platform. This requires keyword research and strategy to ensure your channelâ€™s content targets the proper keywords and uses the correct titles and descriptions for your target audience. SEO stands for search engine optimization. It is part of a broader digital marketing strategy, and it helps improve your websiteâ€™s ranking on search engines by optimizing areas of your website. SEO is not a one-size-fits-all marketing tool, either. It is a constantly evolving, long-term game that requires staying up to speed with competitors and search engine algorithm updates. YouTubeâ€™s SEO algorithm refers to the rules, metrics, and measures the platform uses to rank and recommend videos to viewers. It considers keywords, video length, engagement, views, watch time, and relevance to the viewerâ€™s interests. Understanding and optimizing for YouTube SEO can help content creators increase their visibility, reach, and audience on the platform. Although we may have yet to learn exactly how the algorithm works â€” some consider it a â€œblackboxâ€ like Googleâ€™s algorithm â€” YouTube providescommunity guidelines and policiesto help content creators benefit from YouTubeâ€™s massive audience. I recommend reading patents and white papers and staying updated with YouTubeâ€™s Creator Academy. There is no doubt that YouTubeâ€™s platform can help you expand your audience reach in addition to other social media platforms and search engines. YouTube boasts an astounding 2.1 billion active users worldwide and the platform saw more than 75 billion visits in 2022, according toStatista. Those numbers make YouTube SEO an essential strategy for content creators looking to increase their visibility and reach on the platform. Some key benefits of YouTube video SEO include higher video rankings, increased traffic, better engagement with your audience, and, ultimately, more conversions and revenue. With the right approach and techniques â€” all of which weâ€™re including in this article â€” you can leverage your YouTube SEO strategy to boost your channelâ€™s growth and success. Optimizing your videos for search engines is essential to improve your YouTube channelâ€™s performance meeting your goals. Hereâ€™s a step-by-step checklist of best practices to follow if you want your content to rank higher on YouTube and search engines like Google. To identify your nicheâ€™s most relevant and popular search terms, you must conduct thorough keyword research to help you create your content, titles, and description. This process is a vital component of any SEO strategy, whether you are publishing YouTube content or producing product landing pages for an ecommerce client. Keyword research provides insights into the content users are searching for and reveals gaps within your channel to help expand your video playlist and other helpful YouTube features. In addition, some tools likeSEMRushandAhrefscan help you find question-based keywords for usersâ€™ most searched topics. Ahrefs actually provides YouTube search volume in theirKeyword Explorer tool, which is very helpful given that YouTube search behavior differs from Google search. Tip: Consider question-based keywords when conducting keyword research; the most common search results for videos are for informational content, such as â€œhow-toâ€ informative content. Like with any content optimization, the titles and descriptions are fundamental elements that should always include your target keywords. You can also utilize â€œvideo tagsâ€ on YouTube as a way to utilize more related keywords pertaining to the video. Enhance the accessibility of your videos by enabling subtitles/closed captions and uploading transcripts, which may help improve search engine rankings further. For example, when users with hearing impairment engage with your video, you can improve their experience by providing subtitles/closed captions. In addition, by uploading the video transcript, you ensure that the words match what the video says. This helps to avoid errors from allowing the search engine to translate for you. When you offer accessibility options, youâ€™re signaling to YouTube that your video is engaging for a range of audiences. To further improve your performance on YouTube, you can encourage your audience to engage with your content by enabling likes, comments, and shares. When more viewers engage with your videos, there is a greater chance of getting more views and growing your audience. While itâ€™s not entirely clear which factors directly influence a videoâ€™s success, research regardingYouTubeâ€™s ranking factorsby Brian Dean from Backlinko has shown that engagement signals, among others, can give YouTube a better understanding of your contentâ€™s relevance and value. Comments can sometimes lead to offensive and negative interactions, but YouTube has made comment sections easier to manage by limiting certain words or terms. This prevents users from leaving hateful or harmful comments that serve no purpose. Itâ€™s essential to ensure your audience actively enjoys its time with your content, but it goes beyond preventing comment wars. You can engage with your audience by pinning notable comments and by responding in the comments to any concerns or positive feedback. These signals further indicate that users spend time with your videos, which is a vital sign to the YouTube search engine algorithm. The thumbnail is the first thing a user sees when searching for content on YouTube and when looking at suggested videos on the homepage or on the right-side panel when viewing content. A well-crafted thumbnail can help your video stand out, increase your CTR, and improve the success of your video and channel as more users see your content. When optimizing your video thumbnails, considering the following elements: YouTube provides users with features that help improve the video experience and promote other content on your channel. These features, such as cards and end screens, can point users to relevant videos â€” including your own. YouTube rewards channels and videos that keep users on the platform for extended periods, which it measures with the â€œwatch timeâ€ metric. Optimizing the video experience can encourage more views and increase the watch time on your platform. End screens can also enhance CTA by asking users to subscribe to your channel. Subscriptions lead to more views and an increase in watch time, which improves your ability to hit your KPIs. Once you upload your video and are ready to share it, promote your video on social media and other relevant platforms to increase its visibility and reach. While social media isnâ€™t a direct ranking factor, promoting your video on social media, and on your website, can help drive more audience to your content/channel. When your videos gain more views, this can have a direct impact on ranking signals such as watch time and audience retention rate. Audience retention rate is also an important metric as it provides YouTube with insights into how many viewers stay till the end of your video. Higher retention rates mean users enjoy your content. As content creators, you no doubt have an audience outside of YouTube â€” and those people should know when you post a new video to your channel. Your videoâ€™s first 24 hours can determine its success, and you can actually track its progress in that time period in YouTube Analytics. Staying within the strategy of increasing watch time, playlist optimization can also lead to more views and users spending more time with your content. Here are some SEO tips to follow as you optimize your playlist: Your channelâ€™s homepage is an excellent opportunity for YouTube SEO optimization. Optimizing your homepage lets YouTubeâ€™s search algorithm know more about your content and your channel, allowing it to pick up on target keywords to further improve your video search results. Here are some areas to optimize: Optimizing your videos for search engines is crucial for improving your YouTube channelâ€™s performance and reaching your goals. By following this step-by-step checklist, you can enhance the visibility and engagement of your content on YouTube and increase your audience reach. Like traditional search engine optimization, YouTube SEO is a long-term game. Staying up to date with algorithm updates and community guidelines can help ensure your content is discoverable and successful on the platform. Are you looking for more help with YouTube SEO?Reach out to our team of expertsto find out how we can make your YouTube channel reach its full potential.   We provide digital marketing solutions for many of the worldâ€™s largest brands. San Francisco â€“ Vancouver â€“ Toronto â€“ NYC â€“ London â€“ Hong Kong (Source: https://www.ayima.com/insights/youtube-seo-checklist.html)\n",
            "3. Following handlesfor easier IDs and mentions, YouTubenow offersQR codes as another way to share channels. If you have a channel, go to the You tab on Android or iOS and scroll the carousel underneath your handle for â€œShare channel.â€ YouTubeâ€™s share sheet has added â€œQR codeâ€ alongside Copy link, Quick Share, and other apps. Youâ€™re taken to a fullscreen page that notes the channel name and handle. The channel logo appears at the center of the QR code with a YouTube logo underneath it. (Chrome also has a QR code share option that features a dinosaur at the center.) You can screenshot or â€œSave to camera rollâ€ for just the QR code.Â Thatâ€™s helpful if you plan on putting it out in the world, especially physically. YouTube offering a first-party solution, with some branding, is better than having creators turn to third-party solutions. Meanwhile, you can access the QR code for any channel by â€œtapping the 3-dot menu on a channel page > Share > QR Code.â€ We hope this update makes it easy for you to share your channel with anyone who may want to watch your content FTC: We use income earning auto affiliate links.More. Check out 9to5Google on YouTube for more news: YouTube is Google's massive video streaming platâ€¦ Editor-in-chief. Interested in the minutiae of Google and Alphabet. Tips/talk: abner@9to5g.com Manage push notifications (Source: https://9to5google.com/2024/08/28/youtube-qr-codes/)\n",
            "\n",
            "You: What is Navboost\n",
            "\n",
            "ðŸ” Top Matches:\n",
            "12. #WTSFest Hubs Initiatives Speaker line-ups live for WTSFestLondon&PortlandEarly birds live forBerlin,Philadelphia, &Melbourne Author:Emina Demiri-Watson Last updated:03/07/2024 May was eventful for SEOs in many ways! Google launched AI Overviews, and of course there was the infamous Google API leak. Rand Fishkin received an email on May 5th from an anonymous source claiming to have access toa massive leak of API documentationfrom inside GoogleÃ¢Â€Â™s Search division. Rand meticulously examined the documents, cross-referencing them with known facts and consulting with SEO experts and former Google employees. Mic King provided further analysis bydigging deeper into the leaked documentationand shedding more light on the potential implications for search engine optimisation. Since then, weÃ¢Â€Â™ve had confirmation (of a kind) from aGoogle spokesman emphasising that it Ã¢Â€Âœlacks contextÃ¢Â€Â.And, the originalanonymous source revealed himself to be Erfan Azimi. The usual caveats apply: the leaks do not tell us what factors Google is using to rank web pages. But that doesn't mean we shouldnÃ¢Â€Â™t be digging deep into the documentation and seeing what we can learn from it. If you havenÃ¢Â€Â™t done so already, IÃ¢Â€Â™d recommend checking outDr Marie HaynesÃ¢Â€Â™ series of articles about the leak. She starts off by explaining what the documents which have been leaked actually are: Ã¢Â€ÂœThese documents are not code that is used in GoogleÃ¢Â€Â™s systems. They are documents to help developers who are building with Google's AI on the Cloud PlatformÃ¢Â€Â¦. These arenÃ¢Â€Â™t ranking algorithms. Yet, we may be able to learn about ranking by studying them.Ã¢Â€Â I tend to agree. Just because itÃ¢Â€Â™s not an actual ranking document, doesnÃ¢Â€Â™t mean it is not useful. This is not an article about Ã¢Â€Â˜the truthÃ¢Â€Â™ or one that claims to know the secrets of the algorithm. Instead, IÃ¢Â€Â™ll be digging deeper into what this documentation might teach us about how to optimise video content. After all,YouTube is the second-most visited site on the internetand itÃ¢Â€Â™sforecasted to grow by 24.9% (232.5 million users)between 2024 and 2029. At the same time, GoogleÃ¢Â€Â™s SERPs have become increasingly diverse as well, withvideos being featured 24.6%of the time, sometimes appearing above the Ã¢Â€Âœ10 blue linksÃ¢Â€Â. From a personal point of view, I also wanted to see if the document is useful to help our recently launched video series Ã¢Â€ÂœSEOÃ¢Â€Â™s Getting CoffeeÃ¢Â€Â become more visible in search. Navboost is Google's advanced web search system that employs click data to either boost or demote rankings. The clue is in the name. I first heard about NavBoost in 2020 during theDOJ Antitrust Trialwhere it was mentioned together with another supposed serving system called Glue. During the trial, Pandu Nayak, a VP of Search at Google, testified that Navboost has been around since 2005. Previously it tracked a rolling 18 months of click data, which has now been reduced to 13 months of data. With this new leak exploding, it was time to dig deeper into it. And, what a rabbit hole it turned out to be. Unsurprisingly, NavBoost is mentioned in reference to video content in the leaked documentation Ã¢Â€Â“ YouTube in particular has always tracked user behaviour, and the algorithm is openly based on this. Elements such as: previous videos watched; matching based on similarity of videos - e.g. what you would likely watch based on previous behaviour; and time spent watching videos on a specific topic or a channel are allpart of the personal recommendation algorithmon YouTube. In fact, YouTube specifically notes that theypay attention to the users and not the video. But how relevant is this when we are talking about video content in the Google SERPs? Two interesting places Navboost pops up in relation to video are both connected to anchors: The YouTube attributes refer to three types of queries: LetÃ¢Â€Â™s start with NavBoost queries. To help me understand what these might be, I usedMic KingÃ¢Â€Â™s article on the leak. To understand NavBoost, as Mic points out, you need to look back to the Panda update. Panda essentially creates a \"modification factor\" to adjust how important specific resources (like videos or web pages) are. The Panda modification factor is calculated using: The modification factor (M) is calculated using this formula:M=IL/RQ IL is the number of different websites linking to your video, and RQ is the number of search queries that are related to your video. I suspect that Reference Queries are likely what the documentation on YouTube refers to as NavBoost queries. They are search terms people have used in the past that are recognised as being related to your video. For example, imagine you have a YouTube video titled \"How to Bake a Chocolate Cake.\" In this example, the system would calculate the modification factor (M) as follows: M=10/50 =0.2 This factor helps the system understand how well-linked your video is compared to how often it is searched for. A higher modification factor would mean more independent links per reference query, potentially boosting the video's visibility in search results. If we consider that something like this is indeed part of how video search works, then NavBoost queries are the search terms and navigation patterns that help the system understand which videos are related to which search queries. For example, if people often search for \"chocolate cake recipe\" and your video frequently comes up as a top result, this query would be considered a NavBoost query. The second term I found interesting is Ã¢Â€Â˜anchor queriesÃ¢Â€Â™. IÃ¢Â€Â™ve never considered videos to have anchors and the only thing that comes to mind which seems plausible here are YouTube video chapters. YouTube video chapters allow users to skip to different sections of the video: Source: Example of chapters in our SEOs Getting Coffee podcast Applied to our cake-baking example video - let's say it has the has the following chapters: 00:00 Introduction 00:45 Ingredients 02:30 Preparation 05:00 Cooking 07:45 Serving Tips 09:00 Conclusion The user might want to skip the intro and go straight to the cooking chapter. YouÃ¢Â€Â™ll notice I added timestamps here. YouTube can automatically create chapters such as these or you can add these to your YouTube description manually and add the timestamps to tell YouTube how to make the sections. If we go with the logic that anchors are video chapters, then anchor queries are those that are related to your video chapters. Now that we know the main terms, let's look at the features themselves and what YouTube content creators can do to optimise their videos. Anchor Text Anchor text, is the chapter text (i.e. the names you give your video chapters). This is crucial because it identifies specific segments of a video that are particularly relevant to certain queries. NavBoost Text NavBoost Text refers to the NavBoost query text. Essentially it's the NavBoost query user interaction data + common navigation patterns) that enhances the chapters. This helps surface the most relevant parts of a video based on how users typically interact with the content. Source This is how the NavBoost query was generated. Yes, thatÃ¢Â€Â™s likely the most murky part. My hunch is that this has to do with the reliability and accuracy of the NavBoost query. Possibly, there is some difference between the different ways they are generated that provides deeper context. Which in turn builds more or less trust? The second interesting mention of NavBoost is related to rank embedding. Rank embedding is a concept straight out of machine learning. The Rank part, as the name itself suggests, relates to sorting documents (in this case videos) based on a predicted relevance score to the query. ThatÃ¢Â€Â™s the simple explanation. Behind this is of course a mathematical equation thatÃ¢Â€Â™s not that simple. Typically, ranking models predict a relevance score s = f(x) for each input x = (q, d) where q is a query and d is a document. Then the relevance score is what determines the sorting (the ranking). The higher the score, the better the rank. Source: Learning to Rank: A Complete Guide to Ranking using Machine Learning The second part that needs explaining is the concept of Embedding. This relates to one of the approaches used to implement the scoring model. Specifically,the Vector Space Model. I first heard of the concept of embedding in theexcellent intro to LLMÃ¢Â€Â™s by Britney Muller. Computers don't understand words like we do. Instead, every word is tokenized, translated into a string of numbers. These tokens are then converted into dense numerical vectors. This allows the computer to understand the relationships between the tokens (words). HereÃ¢Â€Â™s agreat example from Britney: Ã¢Â€ÂœImagine every word or token being transformed into a multi-dimensional vector that captures its relationship with other words. This is the crux of embeddings. When we perform operations on these vectors, like the classic example of the vector representation for the word Ã¢Â€ÂœKing,Ã¢Â€Â. Ã¢Â€Â”If you subtract the vector Ã¢Â€ÂœmanÃ¢Â€Â from the vector for Ã¢Â€ÂœKingÃ¢Â€Â and add the vector for Ã¢Â€ÂœWoman,Ã¢Â€Â it yields a strikingly similar vector for Ã¢Â€ÂœQueenÃ¢Â€Â. Similarly, if you subtract the vector for Ã¢Â€ÂœstateÃ¢Â€Â from that of Ã¢Â€ÂœCaliforniaÃ¢Â€Â and add Ã¢Â€ÂœcountryÃ¢Â€Â, the closest vector might correspond to Ã¢Â€ÂœAmericaÃ¢Â€Â. Pretty wild, right!? Keep in mind that these relationships arenÃ¢Â€Â™t always universally valid and are heavily influenced by the specific training data and algorithms used.Ã¢Â€Â LetÃ¢Â€Â™s now put the two terms back together again: Rank Embedding. RankEmbed is an approach used in machine learning that basically relates to how documents are represented in a vector space. The distance between vectors represents the similarity or relevance between the items. In the context of this particular model from the leak, rank embedding (rankembed) similarities measure how closely related different elements (such as video anchors, NavBoost queries, and original query candidates) are to each other within the context of search and recommendation algorithms. Each attribute is a clue to how this is done: anchorReSimilarity -This attribute represents the RankEmbed similarity between the rankembed neighbour (a related or similar item in the rank embedding space) and the video anchor (specific segments or points within the video). High anchorReSimilarity means that your video chapters (anchors) closely match, while low anchorReSimilarity is the opposite. navQueryReSimilarity -This is where the user aspects come into play. Coming back to what we said about NavBoost queries being those which are enhanced by user data, this measures the RankEmbed similarity between the RankEmbed neighbour and the top NavBoost query of the video. reSimilarity -This represents the RankEmbed similarity between the rankembed neighbour and the original query candidate, i.e. the initial query that the user searched for. Well we can't know exactly, but if we consider that NavBoost is part of the equation when it comes to your video chapters then there are a few things creators can do. DonÃ¢Â€Â™t rely on YouTube to automatically set your chapters. Instead, think about how to break down your video into chapters in a way that will bring you more visibility. Create clear, concise segments that include relevant keywords and phrases. Check which keywords are popular and add those to your video chapters. Make sure those keywords are included in spoken content, on-screen text, and subtitles. Then use timestamps in video descriptions to highlight key segments, making it easier for YouTube to identify and use these optimised anchors in search results. This one is a no-brainer. NavBoost is all about user behaviours and if your content is flat to start with it simply won't work. Create content that keeps viewers engaged. Higher engagement rates signal to YouTube that the content is valuable. Go beyond simply thinking about an engaging topic, and guide your viewers to engage. For example, you could include compelling hooks and clear calls to action at strategic points in the video. This will not only get you visibility of YouTube, something we already know, but it should boost your videos in search as well. After your video has been up for a while, use data to refine this engagement. YouTube Analytics lets you analyse user retention and behaviours. This will help you understand which chapters are most engaging. Those are the ones you should optimise even further. Encourage user interaction through comments, likes, and shares. This will provide additional data for algorithms to understand and enhance the relevance of your content. Make sure your video's metadata is comprehensive and accurate. This includes titles, descriptions, tags, and closed captions. Interacting with your audience through comments and community posts can help generate more data points for use in NavBoost queries. Pay attention to your transcripts and subtitles. Even when using auto-creation, make sure you check the most important chapters and the keywords connected to them. You donÃ¢Â€Â™t want those to be misspelt. Our initial video \"How to Bake the Perfect Chocolate Cake\" had the following video chapters. Now letÃ¢Â€Â™s optimise it: Those chapters are not optimised currently. We can add some keywords into them that will help the system understand the video better and how it relates to other terms in this space. Example: Rather than simply using Ingredients we can use something like: \"00:45 Ingredients: Best Chocolate for BakingÃ¢Â€Â WeÃ¢Â€Â™ve optimised the chapters in the description. Now let's look at how we can push this further with NavBoost queries. There are 3 ways we can do this: Step 1:Go to YouTube Studio Example of YouTube Studio Dashboard Vixen Digital Step 2: Navigate to the Analytics section and click on Advanced Mode in the right corner Step 3: Check the Traffic Source and choose YouTube Search. Digging into the rest of the sources can also be useful but unfortunately, Google Search thatÃ¢Â€Â™s listed under External wonÃ¢Â€Â™t give you a query breakdown. Step 4: Check the search terms that led viewers to your videos. Example: one ofour videos.Ã‚Â This is for a GA4 tutorial. The next step for us is to review, combine with other keyword research and optimise into chapters. Applying it to our delicious cake-baking video example, letÃ¢Â€Â™s say we noticed that the search \"easy chocolate cake tutorial,\" is popular. We can now make sure one of our video chapters includes this phrase and we can add it into the description. We now know that engaged users help our rankings. LetÃ¢Â€Â™s make sure our baking video actually engages people! WeÃ¢Â€Â™ll edit our video and ask viewers to comment on their favourite cooking chocolate brands during the \"Ingredients\" segment. Using YouTube Analytics, we know the Cooking chapter is the most engaging one for viewers. So weÃ¢Â€Â™ll add a subscribe CTA to it. Or better yet, letÃ¢Â€Â™sadd that Ã¢Â€ÂœSubscribe to all of our videosÃ¢Â€Âjust likePreppy Kitchenhas done. The basic elements can be tweaked as well; for example,our title could be more comprehensive: \"How to Bake the Perfect Chocolate Cake - Easy Chocolate Cake Recipe Tutorial.\" We could also incorporate user navigation insights into the description. For example we might mention a phrase like: \"cooking chocolate cake\" within the video description. I started digging into this because I understand the importance of a video strategy in todayÃ¢Â€Â™s marketing and the prominence of YouTube in user journeys. And, I wanted more viewers to visit ourSEOÃ¢Â€Â™s Getting Coffee podcast. Will this leak completely change the strategies we employ in YouTube or Google Video Search? No. But there is no doubt that the leak hides a lot of ideas for optimising our video content. Useful ideas which will help our viewers better understand, engage with, and enjoy our videos. Emina Demiri-Watson - Head of Digital Marketing, Vixen Digital Emina has over 10 years of digital marketing experience both in-house and agency side. She is the Head of Digital Marketing at a Brighton-based digital marketing agency Vixen Digital, and co-hoststhe SEO Getting Coffee podcast. Subscribe to the WTSNewsletter (Source: https://www.womenintechseo.com/knowledge/digging-into-the-video-content-modules-of-googles-api-leak/)\n",
            "23. Get the fastest performancefor your website. Once you start with NitroPack, you can freely choose your integration platform. Everything you need to know aboutNitroPack features and compatibilities. Discover more about NitroPack's features Use NitroPack with other plugins Whether you run a blog oran agency, we have apartnership opportunity for you! Suitable for freelancersand agencies Suitable for publishers, educators, and influencers. The place to learn how toimprove your web performance,how to get the most out ofNitroPack, and what is comingnext to our product. Best practices to elevateyour web performance. All your NitroPack questionsanswered in one place. Behind-the-scene videoseries on all things NitroPack. Interaction to Next Paint (INP) is nowan official Core Web Vital, replacing First Input Delay (FID) as the new responsiveness metric.  All FID improvements you've previously made will serve as a great foundation. However, INP introduces new performance challenges, and in the following lines, you will learn exactly how to deal with them in order to provide your visitors with an exceptional user experience. Read on. INP assesses a page's overall responsiveness to user interactions by observing the latency of all qualifying interactions during a user's visit to a page. The final INP value is the longest interaction observed. The interactions that play a part in INPâ€™s calculations are: Similar to the otherCore Web Vitals, your INP score can be in one of the three thresholds:  To guarantee that you achieve this objective for the majority of your users, it is recommended to assess the 75th percentile of page loads, segmented across mobile and desktop devices. If you want to learn more or brush up your knowledge about INP, read our article onthe new responsiveness metric. If you want your INP score to go from poor to good, you need to understand interaction latency. So what exactly is interaction latency? Interaction latency refers to the delay or lag experienced between a user's input or action and the resulting response or output on the screen. It is a crucial factor in determining your site's responsiveness and perceived performance. Three primary components contribute to interaction latency: Input delay refers to the time between when a user starts interacting with the page and when the associated actions or event callbacks begin to execute. It includes the physical or technical delays caused by the input device (e.g., keyboard, mouse, touchscreen) and the system's input processing mechanisms. Once the user input is received, the system must process it to determine the appropriate response or action. Processing time refers to the duration required for the system to analyze and interpret the input data, perform any necessary calculations or operations, and generate the output or response. After the system has generated the output or response, there is typically a delay before it is presented to the user. Presentation delay encompasses the time it takes for the system to update the display, render graphics or user interfaces, and deliver the output to the user interface or output device.   If you need more information, you can check Jeremy Wagnerâ€™s presentation at JSConf Korea 2022: Understanding and optimizing the interaction latency can provide a seamless user experience and fix your INP scores. But before that, letâ€™s take a look at the main culprits for high interaction latency and bad INP scoresâ€¦ Although INP is labeled aspending,this does not mean you should enter the optimization process without a strategy. The first thing you need to do is learn what the main INP culprits are, so you can handle them effectively. Here are the main reasons for theâ€œINP issue: longer than 200msâ€error message: Everything that a browser does is considered a task. This includes rendering, parsing HTML, running JavaScript, and anything you may or may not have control over. Themain threadis where the browser does most of the work needed to display a page. And while there might be dozens of tasks that need to be executed,the main thread can only process one task at a time.  But thatâ€™s only half of the problem. The other half is thatif a task takes more than 50 milliseconds to be executed, itâ€™s classified as along task. Considering that the main thread can handle one task at a time, the longer the task is, the longer the browser will be blocked processing it. In other words, if the user is attempting to interact with the page while a long task runs, the browser will be delayed in fulfilling the request. The result is - interaction latency and a lower INP score. Another reason for failing INP is having a large DOM size. TheDocument Object Model (DOM)is an inseparable part of every web page. The DOM is a representation of an HTML document structured as a tree. Each branch in the tree terminates at a node, and each node contains objects. Nodes can represent different parts of the document, such as elements, text strings, or comments.  The DOM itself isnâ€™t a problem, but its size might be. A large DOM size impacts a browser's ability to render a page quickly and efficiently. The larger the DOM, the more resource-intensive it is to initially display the page and make subsequent updates during the page's lifecycle. Simply put: If you want a page to respond quickly to user interactions, ensure your DOM includes only the necessary elements. You might be wondering what â€œnecessaryâ€ means.According to Lighthouse, a page's DOM size is excessive when itexceeds 1,400 nodes. So make sure to stay within this limit. Otherwise, you might see the following error in yourPageSpeed Insightsreport:  To understand why client-site rendering might cause poor INP scores, we need to explain how it differs from the server-side rendering of HTML. The traditional page load involves the browser receiving HTML from the server on every navigation. What happens in the background when a person decides to load a page is: The key here isâ€œin chunks.â€ When the browser receives the first chunk of HTML, it can start parsing it. But as we know, parsing HTML is a task the main thread handles. However, after each chunk is processed, the browser takes a break from parsing and allows other tasks to be performed. This prevents long tasks that could slow down the browser.  Instead, it can start rendering the parts of the page that have already been parsed, so the user sees a partially loaded page sooner. It can also handle any user interactions that occur during the initial loading of the page. In other words: This approach translates to a better Interaction to Next Paint (INP) score for the page. On the contrary, if your website uses thesingle page application (SPA)pattern, which dynamically creates large parts of the HTML/DOM on the client with JavaScript, you can expect negative effects on your INP score. In client-side rendering, the server sends a small chunk of basic HTML to the client. Then the client takes care of filling in the main content of the page using data it fetches from the server. All future navigations are handled by JavaScript, fetching new HTML from the server and dynamically updating the page without fully reloading it. Unfortunately, when it comes to JavaScript tasks on the client side, they are not automatically chunked up. This can lead to long tasks that block the main thread, potentially affecting your page's Interaction to Next Paint score. Therefore, client-side rendering can hurt the loading and interactivity of your page. If you need additional info on the pros and cons of server-side vs. client-side rendering, check out this video: Now that you know some of the main culprits, letâ€™s proceed with measuring your INP score and identifying slow interactions. The next step in the INP optimization journey is to measure your site's performance and identify any slow interactions. Similar toFirst Input Delay, INP is best measured in the field â€“ examining how real users experience your website. The optimal testing process would look like this: We saidoptimalbecause, in some cases, your site might not have field data (also known as Real User Monitoring (RUM) data). However, this doesnâ€™t mean you should give up optimizing your INP score. You need to take a different approach and leverage the available lab tools.  Letâ€™s take a look at both scenarios and explain how to take most of your field andlab data. Ideally, you'll want to havefield datawhen you start improving your siteâ€™s responsiveness. Relying on RUM data saves you a lot of time figuring out which interactions need to be optimized. Furthermore, lab-based tools can simulate certain interactions but cannot fully replicate real-world user experiences. When gathering INP field data, you'll want to capture the following to give context to why interactions were slow: If youâ€™re asking yourself: How am I supposed to capture all of these things? Donâ€™t worry. All of the data is exposed in theweb-vitals JavaScript library. You can checkGoogleâ€™s step-by-step guideon how to leverage the web-vital library and even how to transmit INP data straight to your Google Analytics. Also, even if youâ€™re already collecting data with a third-party RUM provider, consider comparing it withChrome UX Report (CrUX) data, as there are differences in the methodologies they use. Field data is the most reliable source for measurement. However, as we said, it is not always available. But thereâ€™s no need to worry because you can still measure and identify interactions to improve with the help of lab data. You can use eitherLighthouseorPageSpeed Insightsto run some performance tests. The metric you should keep an eye out for isTotal Blocking Time (TBT). TBT is a metric that assesses page responsiveness during load and correlates very well with INP. A poor TBT score is a signal there are interactions that might be slow during page load.  Hereâ€™s how you can reproduce slow interaction with lab tools: TheWeb Vitals Chrome Extensionis one of the easiest ways to measure your siteâ€™s interaction latency. Hereâ€™s what you need to do to retrieve useful information: Finally, open the Chrome DevTools console and begin testing. You'll receive helpful console logs giving you detailed diagnostic information for the interaction.  To get even more information about why interaction is slow, you can use theperformance profiler in Chrome DevTools. Just do the following: To quickly identify performance issues, check the activity summary at the top of the profiler when the profile populates. Look for red bars in the activity summary, indicating instances of long tasks during the recording. These red bars help you pinpoint problem areas and focus your investigation. Lighthouseâ€™s timespans mode is the less intimidating alternative to the DevTools performance profiler. Hereâ€™s how to use it: You will be presented with a list of failed and passed audits. When you click on them, a drop-down menu will appear, and you can see a breakdown of time spent during interaction divided by input delay, processing time, and presentation delay. Source:Google Now that you know what to work on, itâ€™s time to roll up your sleeves and begin optimizing.  To guarantee your site agoodINP score, you need to ensure that each interaction event runs as fast as possible. Hereâ€™s how to achieve it: 1. Avoid recurring timers that overwork the main thread setTimeoutandsetIntervalare commonly used JavaScript timer functions that can contribute to input delay.setTimeoutschedules a callback to run after a specified time, and while it can help avoid long tasks, it depends on when the timeout occurs and if it coincides with user interactions. setInterval, on the other hand, schedules a callback to run repeatedly at a specified interval. Because of that, it is more likely to interfere with user interactions. Its recurring nature increases input delay and can affect the responsiveness of interactions. If you have control over the timers in your code, evaluate their necessity and reduce their workload as much as possible. 2. Avoid long tasks As you already know, long tasks block the main thread, preventing the browser from executing the interaction events. To enhance your siteâ€™s responsiveness, it is important to minimize the workload on the main thread and considerbreaking up long tasks. By breaking up long tasks into smaller chunks, the main thread gets an opportunity to handle other tasks and respond to user interactions more quickly. Additionally, breaking up long tasks helps avoid the \"jank\" effect, where animations and transitions on the page become choppy or stutter due to the overwhelmed main thread. By ensuring that each task completes within a shorter timeframe, the page can maintain a smoother visual experience for the user.   3. Avoid interaction overlap Interaction overlap means that after a visitor interacted with one element, they make another interaction with the page before the initial interaction has had a chance to render the next frame. For instance, this can happen when users are typing in form fields, leading to numerous keyboard interactions within a brief timeframe. You can optimize the process by: 1. Consider removing the unnecessary callback Is the expensive event callback truly necessary? If not, consider removing the code entirely, or if that's not possible, delay its execution until a more suitable time. 2. Defer non-rendering work Long tasks can be broken up by yielding to the main thread. When you yield to the main thread, you essentially pause the current task and split the remaining work into a separate task. This allows the renderer to handle updates to the user interface that were processed earlier in the event callback. By yielding, you enable the renderer to execute pending changes and ensure a smooth and timely user interface update. 1. Reduce DOM size A large DOM size is a surefire way to fail the INP assessment. So to ensure that wonâ€™t happen, you need to reduce your DOM size, or to put it another way â€“ you need toreduce DOM depth. Aim for a DOM depth of no more than 1,400 nodes. You can achieve it by incorporating the following techniques: 2. Avoid excessive or unnecessary work in requestAnimationFrame callbacks TherequestAnimationFramemethod tells the browser that you wish to perform an animation and requests that the browser calls a specified function to update an animation right before the next repaint. TherequestAnimationFrame()callback is part of the rendering phase in the event loop and needs to finish before the next frame can be displayed. If you're utilizing requestAnimationFrame() for tasks unrelated to user interface changes, it's essential to recognize that you might be causing a delay in the rendering of the subsequent frame. So avoid using them when unnecessary. 3. DeferResizeObserver callbacks TheResizeObserverinterface reports changes to the dimensions of an Element's content or border box or the bounding box of an SVGElement. ResizeObserver callbacks run before rendering and can potentially postpone the presentation of the next frame if they involve resource-intensive tasks. Similar to event callbacks, it is advisable to defer any unnecessary logic not required for the immediate upcoming frame. Based on all the tests weâ€™ve been running in the last couple of months and all the documentation that Google published on INP, we could say that it strongly resemblesLargest Contentful Paint (LCP). A multi-layered Core Web Vital that has a lot of moving parts. So, since Google first announced the new responsiveness metrics, we started testing and working on features that will improve our clientsâ€™ INP scores. And weâ€™ve been seeing some promising results: With NitroPack, our clients experience an average 36% improvement in INP. And that happened all on autopilot. Just by installingNitroPackand thanks to optimization features like: You can also boost your INP and Core Web Vitals scores without writing a single line of code. Install NitroPackfor freeand experience the improvements for yourself. Niko has 5+ years of experience turning those â€œitâ€™s too technical for meâ€ topics into â€œI canâ€™t believe I get itâ€ content pieces. He specializes in dissecting nuanced topics like Core Web Vitals, web performance metrics, and site speed optimization techniques. When heâ€™s taking a breather from researching his next content piece, youâ€™ll find him deep into the latest performance news. Copyright Â© NitroPack 2025 We use cookies to deliver our services and to analyze traffic.Learn More (Source: https://nitropack.io/blog/post/improve-interaction-to-next-paint-inp)\n",
            "32. Download your copy of SEO Trends 2025 and discover what to be hopeful about in a changing search world. Download this actionable guide and learn how Programmatic SEO can deliver exponential growth for your business. Join us as we demystify the latest trends, from AI to GEO, and provide actionable insights to help you achieve tangible results in 2025. Discover actionable insights for crafting authentic impactful campaigns and enhancing your SEO efforts, while elevating your brand. Join us as we demystify the latest trends, from AI to GEO, and provide actionable insights to help you achieve tangible results in 2025. Discover actionable insights for crafting authentic impactful campaigns and enhancing your SEO efforts, while elevating your brand. Maximize app store visibility & success with this App Store Optimization how-to guide. Discover the key aspects of ASO & how to maximize success in Google Play & Apple App Store. Amobile strategyis critical to your business presence, considering the saturation of mobile devices. With nearly2 million appsin the Apple App Store alone, discoverability is now more important and more challenging than ever before. This is where app store optimization (ASO) comes into play. In this article, youâ€™ll learn: Whether you are new to app store optimization or simply keen to refine your approach to ASO, this post shares practical insights that are proven to maximize app store success. Downloads, usage, and in-app spending continue to rise, but many users prefer to use aselect few apps more consistently. Discoverability has never been harder, but the rewards of locking in loyal users are bigger than ever â€“ so maximizing visibility in app stores is crucial. App store optimization (ASO) describes the process of optimizing the listing pages for your mobile app in app stores like Google Play and Appleâ€™s App Store. You may come across alternative phrases like â€œapp store marketingâ€ or â€œmobile app SEO,â€ but they all refer to the same thing. The goal is to maximize the visibility (and downloads) of your app for relevant searches â€“ basically,SEO for your mobile apprather than your website. In many ways, the optimization process for ASO is very similar to SEO; in others, not so much. Ultimately, ASO aims tomaximize app installswhile product development works on monetization, engagement, retention, etc. An effective app store optimization strategy keeps new users coming in while your development team (hopefully) keeps existing ones active and spending. With the right retention rates, app store optimization acquires the new users you need to drive meaningful growth. The goal of ASO is nearly always app downloads, but supplemental goals can include items such as: If youâ€™re new to app store optimization, it might help to think of it as SEO for your mobile app. Except, rather than optimizing a website to show in search engines, youâ€™re optimizing your mobile app listings for the relevant app stores. In this sense, you could argue ASO is more like optimizing a Google Business Profile to show in Maps and local results. The other key difference is youâ€™ve got two major mobile app stores to optimize for: Google Play and Appleâ€™s App Store. These arenâ€™t the only two app stores worth considering, especially if youâ€™re developing apps for other devices (TVs, games consoles, etc.), but they are the biggest â€“ by far. According toStatista insights from Q3 2022, here are the top three app stores based on the number of available apps: As a result, most ASO guides focus on optimizing app listings for Google Play and Apple App Store. Aside from being the top two platforms, the optimization process is a little different for each. This is mostly due to each app store having its own algorithm â€“ much like different search engines. In practice, most app store algorithms are more alike than they are different. So, the basic principles of app store optimization apply to all of them. However, some stores may use the odd ranking signal that others donâ€™t. To keep this guide simple, weâ€™ll start by running through the most common ranking signals for app stores, in general. Then, weâ€™ll take a closer look at Google Play and Apple App Store to see how theyâ€™re different. The key ingredient missing from many ASO marketing delivery approaches is organic search optimization and integration of app stores within the broader organic marketing mix. There is more overlap between ASO and SEO than direct competition between the two. The integration of these areas, and the application of consistent focus on ASO, can support numerous search marketing gains. You may be surprised to discover that many of the traditional search engine optimization tactics that work for search engine performance, such as Google and Bing, can also be directly applied to ASO. Examples of this include: The biggest marketing mistake, however, when it comes to integrating SEO and ASO is overlooking the role of the website in driving volumes of referral visits directly to your store page and app downloads section. Your website should be seen asthe driving forcebehind leading people throughout theinformation-seeking and buying funnelfrom your main online entity (your website) through to an engaged, ready-to-buy/download audience (your app store). As content levels are limited within the app stores themselves, the more you can leverage your website content to increase app awareness and discovery to build external app authority and visibility, the greater the value, traffic, and downloads your app will receive. Like search engines, app stores donâ€™t reveal the details of their algorithms to the public. That being said, the following seven ranking factors are key, functional components of all major app stores: You can break these ranking factors into three categories: discovery, conversion, and validation. Discoverysignals help app stores connect your app with relevant searches. This includes your app name /title, description, keywords, and other contextual signals. Conversionsignals tell app stores that your listing compels users to download your app â€“ a strong indicator that your listing should show for more relevant searches. Finally, youâ€™ve gotvalidationsignals (engagement, in-app purchases/events, reviews, reports/flags, etc.). These help app stores determine whether users get a positive experience after installing your app. Positive validation signals (strong engagement, positive reviews, etc.) are an even stronger indicator that app stores should show your app to similar users. Optimizing your app listing for visibility is one thing; getting users to actually download your app is something else entirely. The catch-22 here is that installs directly impact your ranking in app stores. The more people install your app, the higher it should rank. This, in turn, should result in more installs, higher rankings once again â€“ and so forth. So, what are the key factors on your mobile app page that determine whether users hit the install button? Here, you can see this in action. Much like SEO, app store optimization is a careful balance of optimizing to maximize visibility in app stores while prioritizing the needs of your users. Google Play and the App Store are more similar than different when it comes to app store optimization. Firstly, the ranking factors are very similar, and the differences are mostly technical â€“ for example, Google and Apple handle keywords differently. Hereâ€™s a quick summary of the main ranking factors for Google Play and the App Store. As you can see, thereâ€™s not much of a difference here â€“ in fact, most of your time will be spent on things like specifications for icons, videos, and other assets for each app listing. As a general rule, Apple is more strict with its developer guidelines and itâ€™s usually harder to get an app approved for the App Store. So, if youâ€™re promoting iOS and Android apps, optimizing your listings for Appleâ€™s guidelines will often satisfy both app stores while maintaining consistency and reducing workload. Now, letâ€™s take a closer look at app store optimization for Google Play and, then, the App Store. To give your app listing the best possible start, youâ€™ll want to dedicate the most time to the following nine elements: Weâ€™ll take a closer look at optimizing each of these elements, but always refer to officialGoogle guidelineswhile managing app listings for Google Play. Optimizing your app title for Google Play will feel familiar if youâ€™re used to optimizing website titles for search. You want to start with the product/branded name of your app and then include a brief description â€“ in no more than a few words â€“ using your primary keyword. You can use up to 30 characters in your app title, but try to keep it as short and punchy as possible. Prioritize accuracy over keyword targeting and highlight the key benefits of using your app. Selecting the right category for your app is essential for matching with relevant searches. For example, letâ€™s say youâ€™re promoting a heart rate monitoring app. In this case, â€œHealth and Fitnessâ€ is the most appropriate category. When users specifically search for â€œheart rate monitor,â€ the keywords in your title are a stronger signal. However, your app category can help your app show for more general searches like â€œhealth and fitness appsâ€ or â€œproductivity apps.â€ Crucially, users can also browse categories in the Google Play store to discover new apps without searching. For more info on selecting the right app category for Google Play, take a look at thisPlay Console Helppage. In Google Play, your app listing includes two descriptions: A short description that shows under theAbout this apppreview and a full description that users can reveal by clicking on the arrow highlighted below.  You can use up to 80 characters for your short description and 4,000 characters for your full description. In your short description, try to describe the core functionality of your app in the most compelling way possible. Accuracy is key here, but you want to convince users to install your app â€“ so highlight the most attractive benefits. Your full description provides a more in-depth summary of what your app offers. Remember that most people wonâ€™t click through to read the full description, and those who do are looking for information, not a sales pitch. Youâ€™ll find Googleâ€™s official guidelines for creating app descriptions under the â€œApp descriptionsâ€ section of thisPlay Console Helppage. App icons show on the left side of search listings in Google Play and the top-right of app listing pages.  These are the most prominent elements on app store results pages. Ideally, you want an app icon that either visually describes the role of your app or leverages your brand image as a differentiator. Designing a unique icon is more challenging if your app has a specific purpose and many competitors â€“ e.g., a heart monitoring app.  If this applies to your app, use design principles like contrast to make your listing stand out from other results. Notice how Pulse Appâ€™s Heart Rate Monitor app stands out from the other listings above? This is thanks to a combination of simple iconography with strong contrast, using a black background to stand out from the white Google Play results page. Compare this to the REPS app, which uses similar iconography without a black background, and the Bodymatter app, which uses a black background but a more complex design. Google Codelabs has an excellent tutorial ondesigning and previewing app icons. It includes best practices and tips for making an icon that stands out on results pages and the latest Android features, such as adaptive icons. Feature graphics show on your app listing page and can also show for branded searches, paid ads, or recommendation sections on Google Play. Until recently, you could only use images as featured graphics, but you can now use promo videos in their place. This is one of the most visible assets on your Google Play listing, so use feature graphics to capture attention and showcase the best of your app. Google suggests: â€œUse graphics that convey app or game experiences, and highlight the core value proposition, relevant context, or story-telling elements if needed.â€ Youâ€™ll find more guidance on creating feature graphics under thePreview assetssection of thisPlay Console Helppage. App screenshots show in the same horizontal panel as feature graphics on your app listing page. Theyâ€™re designed to showcase the best features of your apps while showing users what the in-app experience looks like. You can include descriptive text in your screenshots to emphasize the key benefits of your appâ€™s most important features. Keep things descriptive, though. Google prohibits the inclusion of performative or ranking text in screenshots, such as â€œapp of the yearâ€ or â€œmost popularâ€¦â€ and promotional information like â€œ10% offâ€ or â€œfree account.â€ If your app supports multiple languages, youâ€™ll need to provide screenshots for each language version, including any translated descriptive text. See thescreenshotssection of thisPlay Console Helppage for more info. App ratings show prominently in results and at the top of the app listing pages in Google Play. Besides this, youâ€™ve also got a prominentRatings and reviewssection as the largest element on your listing page. Aside from being a ranking factor, app ratings and reviews are one of the biggest trust factors that help users choose which apps to install. You donâ€™t need perfect review scores but a positive (3.5+ stars) is a great asset for rankings and installs. Your review profile also allows users to view the feedback left by others â€“ and how you respond. Once again, how you deal with user problems is often more important than the scores or feedback itself. Youâ€™ll need a framework in place for generating regular reviewsandreplying to them, engaging with reviewers, and solving user issues. Your replies are also visible, so avoid generic responses â€“ show new, potential users how good you are at dealing with problems. In fact, donâ€™t take inspiration from Googleâ€™s own support team for Google One. Privacy is great, but the tone of the reply below is more dismissive than helpful, and the exact same response appears throughout replies. This feedback can also help you develop a stronger product, and users often edit their reviews, following updates or resolved tickets. Always remember: Long-term revenue is the goal, which starts with quality app experiences, engagement, and retention. Google provides an extensive toolkit for optimizing your mobile app. ItsAndroid vitalsinitiative sets out the most important usability metrics that affect the visibility of your app on Google Play. If youâ€™re used to optimizing websites for search, this will sound a lot like Googleâ€™sCore Web Vitals. The principle Android vitals is similar in terms of performance affecting your search ranking, but this is a far more extensive initiative than Core Web Vitals, as it stands. Android vitals are broken into two key components: Core vitals All other vitals To maximize the visibility of your app in Google Play, keep the user-perceived crash rate below 1.09% across all devices and 8% per device, with the user-perceived ANR rate below 0.47% across all devices and 8% per device. Take a look at the officialAndroid vitalsdocumentation page for more information. For the App Store, weâ€™ve also got nine key elements to optimize, but theyâ€™re not quite the same as Google Play: One of the key differences here is how the two platforms handle keywords. While Google analyzes your whole listing for keywords, Apple provides a single field for you to add keywords. Again, always refer toofficial Apple documentationwhen optimizing listings for the App Store. In the App Store, your app name simply provides a recognizable and memorable name for your mobile app. You donâ€™t need to worry about keywords or descriptive text here â€“ that comes later. For now, concentrate on coming up with an app name thatâ€™s easy to remember and spell while somewhat describing what your app does. Apple offers the following advice: â€œChoose a simple, memorable name that is easy to spell and hints at what your app does. Be distinctive. Avoid names that use generic terms or are too similar to existing app names.â€ You can use up to 30 characters for your app name in the App Store, but try to keep it as short and punchy as possible. As with most app stores, the app icon is one of the most prominent elements as users browse the iOS app store. Apple provides extensivedesign guidelines for app iconsand itâ€™s more strict than most. So, if youâ€™re promoting your app across the App Store, Google Play, and any other platforms, you might want to start with Apple first. In most cases, this makes it easiest to maintain a consistent design across all platforms. Generally speaking, the same design principles apply. Keep it simple and impactful with intelligent use of iconography, color, and contrast. Look at your competitors and try to come up with something that stands out from the other apps your target audience is likely to see. Your app subtitle provides a brief description below the app name. Use this to highlight the purpose and benefits of your app in the most compelling way possible.  This is your first opportunity to excite potential users about your app, so try to make an impression here. Youâ€™ve only got 30 characters to work with, which means punchy subtitles tend to do best. Youâ€™ll want to test and refine your subtitles over time, paying close attention to CTRs and installs as you try different variations. As with Google Play, categories are key for discoverability in the App Store. You can assign primary and secondary categories for iOS apps to help users find your app; the primary category has the strongest weight. â€“ so choose the most relevant one. Apple provides extensiveguidance for choosing app categories. Make sure you follow Appleâ€™s guidance because selecting the wrong categories violates the App Store guidelines. In some cases, you may find multiple categories that match your app. For example, if youâ€™re running a photo-sharing social media app, you could select either Photo & Video or Social Networking as your primary category. In such cases, Apple suggests considering the following: If multiple categories accurately reflect the purpose of your app, youâ€™re unlikely to run into any violation issues. At this point, itâ€™s more a question of which category matches the search and everyday use of your app â€“ not only to maximize visibility but also to set the right expectations for users who install your app (think engagement and retention). While Google Play looks for keywords throughout your app listing (similar to how Google Search analyses web pages), the App Store provides a dedicated keywords field. You can use up to 100 characters to add keywords (separated by commas â€“ no spaces) to help users discover your app. Apple offers the following advice for choosing keywords: â€œChoose keywords based on words you think your audience will use to find an app like yours. Be specific when describing your appâ€™s features and functionality to help the search algorithm surface your app in relevant searches.â€ Apple also recommends considering â€œthe trade-offâ€ between ranking well for less common terms versus ranking lower for popular terms. The most popular keywords may generate a lot of impressions and traffic, but theyâ€™re also the most competitive, which can impact CTRs and installs. Your app description should provide a short, compelling â€“ and informative â€“ description of your app, highlighting its main purpose and benefits. Similar to Google Play, you can use up to 4,000 characters in your app description, but users can only see the first two lines (and most of the third) without clicking to see more. Apple suggests the following: â€œCommunicate in the tone of your brand, and use terminology your target audience will appreciate and understand. The first sentence of your description is the most important â€” this is what users can read without having to tap to read more.â€ If you want to update your app description, youâ€™ll have to resubmit your app listing, so itâ€™s important to try and get this right and only make considered changes. You can also add up to 170 characters of promotional text to the top of your app description. Crucially, you can change this text at any time without having to resubmit your app listing, making this a great place to share the latest news and info about your app â€“ such as limited-time sales, the latest features, or fixes from the last update. App previews are the App Store equivalent of promo videos. You can add up to 30 seconds of footage to illustrate the key benefits of your app and the experience of using it. Again, Apple has strictguidelines and specifications for app previewsâ€“ make sure you tick all the right boxes. As with most things, if youâ€™re listing your app in the App Store and Google Play, getting your app preview approved for the App Store first should mean you can use the same format for Google Play â€“ as long as you include footage from the Android version of your app. You can add up to 10 screenshots to your app listing for the App Store. If you donâ€™t have an app preview, the first one to three screenshots will show in search results, so make sure these highlight the core purpose of your app. In your remaining screenshots, you can focus on the main features or benefits of using your app. Try to stick to one feature or benefit per screenshot to communicate each purpose clearly. Once again, app ratings and reviews are important for maximizing visibility and installs in the App Store. If anything, user reviews are more prominent in the App Store than Google Play, but we canâ€™t say whether this has any meaningful impact on downloads. The same general principles apply here: try to develop a regular stream of reviews and manage a positive app rating. Again, you donâ€™t need perfect scores, but you do need torespond to user reviews and address potential issues. Prioritize negative reviews and respond as quickly as possible with responses that deal with issues â€“ avoid generic, unhelpful responses. App store optimization is an ongoing process that needs ongoing attention. Getting your listings approved for app stores is only the beginning. Maximizing visibility and â€“ more importantly â€“ revenue from your mobile apps requires a complete product development strategy. Here are some final, additional tips to help you drive long-term success from app store optimization: The mobile app industry still shows growth despite smartphone penetration being way past saturation. Smartphones arenâ€™t the only devices in peopleâ€™s lives anymore, either. Apple Vision Pro launched withover 600 compatible apps, opening another space for mobile experiences beyond the confines of traditional smartphones. App store optimization (ASO) will become more complex as new devices and app stores emerge. However, the rewards will also grow, and the companies already mastering ASO for todayâ€™s app stores will be first in line to benefit as emerging technologies bring new opportunities. More Resources: Featured Image: Billion Photos/Shutterstock Lee Wilson is Service Operations Director at Vertical Leap, and has led digital marketing departments since the early 2000â€™s. Heâ€™s ... Conquer your day with daily search marketing news. Join Our Newsletter. Get your daily dose of search know-how. In a world ruled by algorithms, SEJ brings timely, relevant information for SEOs, marketers, and entrepreneurs to optimize and grow their businesses -- and careers. Copyright Â© 2025Search Engine Journal.All rights reserved. Published by Alpha Brand Media. (Source: https://www.searchenginejournal.com/app-store-optimization-how-to-guide/241967/)\n",
            "\n",
            "You: exit\n",
            "ðŸ‘‹ Goodbye!\n"
          ]
        }
      ],
      "source": [
        "def chatbot():\n",
        "    print(\"ðŸ¤– Ask me anything! Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nYou: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"ðŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Search for relevant results\n",
        "        results = search_similar_text(query, top_k=3)\n",
        "\n",
        "        print(\"\\nðŸ” Top Matches:\")\n",
        "        for i, row in results.iterrows():\n",
        "            print(f\"{i+1}. {row['Text']} (Source: {row['Source']})\")\n",
        "\n",
        "# Start the chatbot\n",
        "chatbot()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th1p1CcBLo23",
        "outputId": "0fa1e710-5d99-412f-e56a-2ba1451cac29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ” Top Source Matches:\n",
            "1. https://www.linkedin.com/pulse/how-automate-seo-keyword-research-chai-fisher/\n",
            "2. https://www.searchenginejournal.com/google-search-console-guide/209318/\n",
            "3. https://www.aleydasolis.com/en/search-engine-optimization/ai-prompts-digital-marketing-seo-generator/?ref=marketingpowerups.com\n"
          ]
        }
      ],
      "source": [
        "def search_source_only(query, top_k=3):\n",
        "    # Convert the query into an embedding using OpenAI\n",
        "    query_embedding = client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=query\n",
        "    ).data[0].embedding\n",
        "\n",
        "    # Convert query embedding to the correct format\n",
        "    query_embedding = np.array(query_embedding).astype(\"float32\").reshape(1, -1)\n",
        "\n",
        "    # Search FAISS index for the most similar embeddings\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve only the source column from the DataFrame\n",
        "    sources = df.iloc[indices[0]][\"Source\"].values  # Replace with actual column name\n",
        "\n",
        "    return sources\n",
        "\n",
        "# Example Search\n",
        "query = \"How do I hire contractors globally?\"\n",
        "sources = search_source_only(query)\n",
        "\n",
        "print(\"\\nðŸ” Top Source Matches:\")\n",
        "for i, source in enumerate(sources, 1):\n",
        "    print(f\"{i}. {source}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Zgf258L7tY",
        "outputId": "d52a6675-b27a-46af-e6d8-861984906f20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¤– Ask me anything! Type 'exit' to quit.\n",
            "\n",
            "You: YouTube module\n",
            "\n",
            "ðŸ” Top Source Matches:\n",
            "1. https://9to5google.com/2024/08/28/youtube-qr-codes/\n",
            "2. https://www.ayima.com/insights/youtube-seo-checklist.html\n",
            "3. https://www.womenintechseo.com/knowledge/digging-into-the-video-content-modules-of-googles-api-leak/\n",
            "\n",
            "You: SEO content\n",
            "\n",
            "ðŸ” Top Source Matches:\n",
            "1. https://www.searchenginejournal.com/mobile-friendly-content-tips/\n",
            "2. https://www.searchenginejournal.com/mobile-friendly-content-tips/419615/\n",
            "3. https://www.searchenginejournal.com/mobile-friendly-content-tips/419615/\n",
            "\n",
            "You: Click through Rate\n",
            "\n",
            "ðŸ” Top Source Matches:\n",
            "1. https://firstpagesage.com/reports/google-click-through-rates-ctrs-by-ranking-position/\n",
            "2. https://www.womenintechseo.com/knowledge/digging-into-the-video-content-modules-of-googles-api-leak/\n",
            "3. https://www.seoforjournalism.com/p/topic-tag-pages-audit\n",
            "\n",
            "You: AI \n",
            "\n",
            "ðŸ” Top Source Matches:\n",
            "1. https://www.searchenginejournal.com/youtube-announces-music-industry-partnership-for-responsible-ai/494353/\n",
            "2. https://www.searchenginejournal.com/youtube-announces-music-industry-partnership-for-responsible-ai/494353/\n",
            "3. https://www.aleydasolis.com/en/search-engine-optimization/ai-prompts-digital-marketing-seo-generator/?ref=marketingpowerups.com\n",
            "\n",
            "You: exit\n",
            "ðŸ‘‹ Goodbye!\n"
          ]
        }
      ],
      "source": [
        "def chatbot_source_only():\n",
        "    print(\"ðŸ¤– Ask me anything! Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nYou: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"ðŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Search for relevant sources\n",
        "        sources = search_source_only(query, top_k=3)\n",
        "\n",
        "        print(\"\\nðŸ” Top Source Matches:\")\n",
        "        for i, source in enumerate(sources, 1):\n",
        "            print(f\"{i}. {source}\")\n",
        "\n",
        "# Start the chatbot\n",
        "chatbot_source_only()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4VWZASOO0WP",
        "outputId": "7c3df99e-6d2a-491d-dcaa-744c7611321e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 2.8M\n",
            "-rw-r--r-- 1 root root 2.3M Feb  5 03:19  embedded_data.csv\n",
            "-rw-r--r-- 1 root root 516K Feb  5 02:37 'extracted_text batch2 v2.csv'\n",
            "drwxr-xr-x 1 root root 4.0K Feb  3 14:20  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQfHiKIQO-HX",
        "outputId": "c77add64-c2e9-4210-98d5-46c971b40c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… FAISS index and metadata saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "import pickle\n",
        "\n",
        "# Save FAISS index\n",
        "faiss.write_index(index, \"/content/faiss_index.bin\")\n",
        "\n",
        "# Save metadata (column names) using pickle\n",
        "with open(\"/content/index_metadata.pkl\", \"wb\") as f:\n",
        "    pickle.dump(df.columns, f)\n",
        "\n",
        "print(\"âœ… FAISS index and metadata saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZuQUDlZPAJM",
        "outputId": "ecd82f3c-3bf6-4ff3-8409-3ee4f2c3ab12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 3.2M\n",
            "-rw-r--r-- 1 root root 2.3M Feb  5 03:19  embedded_data.csv\n",
            "-rw-r--r-- 1 root root 516K Feb  5 02:37 'extracted_text batch2 v2.csv'\n",
            "-rw-r--r-- 1 root root 325K Feb  5 03:51  faiss_index.bin\n",
            "-rw-r--r-- 1 root root  253 Feb  5 03:51  index_metadata.pkl\n",
            "drwxr-xr-x 1 root root 4.0K Feb  3 14:20  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KU7QCPZwPEc6",
        "outputId": "c20a05c3-3ac5-48c3-8c9f-665510d4c290"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_0f273804-fed6-4f19-bb59-dcd58b51e7f6\", \"faiss_index.bin\", 331821)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8ee8dacc-bc31-44d7-be5f-ebfd7a297262\", \"index_metadata.pkl\", 253)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download FAISS index\n",
        "files.download(\"/content/faiss_index.bin\")\n",
        "\n",
        "# Download metadata file\n",
        "files.download(\"/content/index_metadata.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Ak3mrpPkqC",
        "outputId": "f0feced1-e7cd-405a-cb0c-74fd4d5543c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z8A7eE8QRv8",
        "outputId": "d2878aaa-3887-4073-dade-d832155ef381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "r-UOLoWPRDon",
        "outputId": "00d9e061-0d4d-4a78-dde3-1937200f7333"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'faiss'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d62f9c30bc45>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define the correct Google Drive path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "import pickle\n",
        "\n",
        "# Define the correct Google Drive path\n",
        "drive_path = \"/content/drive/MyDrive/SEO/Custom GPT project/2.4.2025 embedded data/\"\n",
        "\n",
        "# Load the DataFrame\n",
        "df = pd.read_csv(drive_path + \"/content/drive/MyDrive/SEO/Custom GPT project/2.4.2025 embedded data/embedded_data.csv\")\n",
        "\n",
        "# Load FAISS index\n",
        "index = faiss.read_index(drive_path + \"/content/drive/MyDrive/SEO/Custom GPT project/2.4.2025 embedded data/faiss_index.bin\")\n",
        "\n",
        "# Restore column names\n",
        "with open(drive_path + \"/content/drive/MyDrive/SEO/Custom GPT project/2.4.2025 embedded data/index_metadata.pkl\", \"rb\") as f:\n",
        "    df.columns = pickle.load(f)\n",
        "\n",
        "print(\"âœ… FAISS index and embedded data reloaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktwdwoHoRrZY",
        "outputId": "3ddaf57f-fd66-4b63-9300-640e8b7abf19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhBYkaHIRvT5",
        "outputId": "bbfdf4ef-ca92-49d7-c828-6700ac88ebcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FAISS is installed correctly!\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "print(\"âœ… FAISS is installed correctly!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Haq0knvERy3p",
        "outputId": "5b9690a7-66ae-4c57-d09e-7314403bea07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FAISS index and embedded data reloaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "import pickle\n",
        "\n",
        "# Define the correct Google Drive path\n",
        "drive_path = \"/content/drive/MyDrive/SEO/Custom GPT project/2.4.2025 embedded data/\"\n",
        "\n",
        "# Load the DataFrame\n",
        "df = pd.read_csv(drive_path + \"embeddings_data.csv\")\n",
        "\n",
        "# Load FAISS index\n",
        "index = faiss.read_index(drive_path + \"faiss_index.bin\")\n",
        "\n",
        "# Restore column names\n",
        "with open(drive_path + \"index_metadata.pkl\", \"rb\") as f:\n",
        "    df.columns = pickle.load(f)\n",
        "\n",
        "print(\"âœ… FAISS index and embedded data reloaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import faiss\n",
        "import pickle\n",
        "\n",
        "# Define the correct Google Drive path\n",
        "drive_path = \"/content/drive/MyDrive/SEO/Custom GPT project/2.4.2025 embedded data/\"\n",
        "\n",
        "# Load both CSV files\n",
        "df1 = pd.read_csv(drive_path + \"embeddings_data.csv\")\n",
        "df2 = pd.read_csv(drive_path + \"embedded_data (2).csv\")\n",
        "\n",
        "# Combine them into one DataFrame\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# ðŸ§¹ CLEANING SECTION\n",
        "\n",
        "# Drop any column named 'Embeddings' (capital S)\n",
        "if 'Embeddings' in df.columns:\n",
        "    df = df.drop(columns=['Embeddings'])\n",
        "\n",
        "# Drop unnamed index columns like 'Unnamed: 0'\n",
        "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "\n",
        "# Rename 'Embedding' (capital E) to 'embedding' (lowercase e)\n",
        "if 'Embedding' in df.columns:\n",
        "    df = df.rename(columns={'Embedding': 'embedding'})\n",
        "\n",
        "# Ensure only the 3 expected columns remain\n",
        "df = df.loc[:, ['Text', 'Source', 'embedding']]\n",
        "\n",
        "# âœ… Now restore column names from pickle (if needed)\n",
        "with open(drive_path + \"index_metadata.pkl\", \"rb\") as f:\n",
        "    df.columns = pickle.load(f)\n",
        "\n",
        "# âœ… Load FAISS index\n",
        "index = faiss.read_index(drive_path + \"faiss_index.bin\")\n",
        "\n",
        "print(\"âœ… FAISS index and embedded data reloaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqvL0xt1Pq3_",
        "outputId": "3a603679-9e5d-4840-e0d9-fc183ef46df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FAISS index and embedded data reloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ11gNfWSPbG"
      },
      "outputs": [],
      "source": [
        "def search_source_only(query, top_k=3):\n",
        "    # Convert the query into an embedding using OpenAI\n",
        "    query_embedding = client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=query\n",
        "    ).data[0].embedding\n",
        "\n",
        "    # Convert query embedding to the correct format\n",
        "    query_embedding = np.array(query_embedding).astype(\"float32\").reshape(1, -1)\n",
        "\n",
        "    # Search FAISS index for the most similar embeddings\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve only the source column from the DataFrame\n",
        "    sources = df.iloc[indices[0]][\"Source\"].values  # Replace with actual column name\n",
        "\n",
        "    return sources\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21TiMrNoSkxt"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# Set up OpenAI client\n",
        "client = openai.OpenAI(api_key=\"API KEY HERE")  # Replace with your actual API key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nEa_BgASsHc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def search_source_only(query, top_k=3):\n",
        "    # Convert the query into an embedding using OpenAI\n",
        "    query_embedding = client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=query\n",
        "    ).data[0].embedding\n",
        "\n",
        "    # Convert query embedding to the correct format\n",
        "    query_embedding = np.array(query_embedding).astype(\"float32\").reshape(1, -1)\n",
        "\n",
        "    # Search FAISS index for the most similar embeddings\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve only the source column from the DataFrame\n",
        "    sources = df.iloc[indices[0]][\"Source\"].values  # Replace with actual column name\n",
        "\n",
        "    return sources\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeMEA-9Dbnoo",
        "outputId": "82a55d81-3225-4a8f-d7ba-b0e6e9889094"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¤– Ask me anything! Type 'exit' to quit.\n",
            "\n",
            "ðŸ” Top Source Matches:\n",
            "1. https://www.searchenginejournal.com/google-mobile-first-indexing/346170/\n",
            "2. https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Responsive_Design\n",
            "3. https://www.searchenginejournal.com/ecommerce-guide/must-have-website-features/\n"
          ]
        }
      ],
      "source": [
        "def chatbot_source_only():\n",
        "    print(\"ðŸ¤– Ask me anything! Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nYou: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"ðŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Search for relevant sources\n",
        "        sources = search_source_only(query, top_k=3)\n",
        "\n",
        "        print(\"\\nðŸ” Top Source Matches:\")\n",
        "        for i, source in enumerate(sources, 1):\n",
        "            print(f\"{i}. {source}\")\n",
        "\n",
        "# Start the chatbot\n",
        "chatbot_source_only()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NKNM-nD3pmlXbKMm1WAavXMPiw5vayPQ",
      "authorship_tag": "ABX9TyPlbtHLlbPbZXlhJNh7jo8G"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
